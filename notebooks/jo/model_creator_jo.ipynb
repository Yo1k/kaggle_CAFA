{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Использовать только процессор.\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "# Изменить уровень отображения логов\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "\n",
    "# Корень проекта.\n",
    "DIR_ROOT = Path.cwd().parent.parent\n",
    "sys.path.append(str(DIR_ROOT))\n",
    "import src.model_utils as mu\n",
    "from src.logger import mean_epochs, eval_log_to_json, eval_log_to_table\n",
    "\n",
    "# Путь к удаленной директории с ресурсами: данные, модели и т.д.\n",
    "DIR_REMOTE: Path | None = Path('/home/admin/cafa/resources')\n",
    "\n",
    "if DIR_REMOTE is not None and DIR_REMOTE.exists():\n",
    "    DIR_RESOURCE = DIR_REMOTE\n",
    "else:\n",
    "    DIR_RESOURCE = DIR_ROOT\n",
    "\n",
    "# Путь к директории с подготовленными данными.\n",
    "DIR_PREPARED_DATA = DIR_RESOURCE / 'data/prepared'\n",
    "# Путь к файлу с оценкой моделей для различных экспериментов.\n",
    "PATH_TO_EVAL_FILE = DIR_ROOT / 'experiments/eval.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Утилиты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_shape_and_total_memory(df: pd.DataFrame, prefix: str = '') -> None:\n",
    "    '''\n",
    "    Вывод информации о форме и общем размере занятой памяти\n",
    "    объектаpd.DataFrame\n",
    "    '''\n",
    "    print(\n",
    "        prefix,\n",
    "        f'Shape: {df.shape}',\n",
    "        f'Total memory: {df.memory_usage().sum() / 1024**3:.1f} GB',\n",
    "        '---',\n",
    "        sep='\\n',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных (признаков и целей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "Shape: (142246, 1024)\n",
      "Total memory: 1.1 GB\n",
      "---\n",
      "y:\n",
      "Shape: (142246, 1500)\n",
      "Total memory: 0.8 GB\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_FEATURES = DIR_PREPARED_DATA / 'train_features.csv'\n",
    "PATH_TO_LABELS = DIR_PREPARED_DATA / 'train_lbls_top1500_goterms.csv'\n",
    "# Загрузка признаков.\n",
    "x = pd.read_csv(PATH_TO_FEATURES)\n",
    "# Загрузка целей.\n",
    "y = pd.read_csv(PATH_TO_LABELS)\n",
    "y = y.astype('int32')\n",
    "print_shape_and_total_memory(x, 'x:')\n",
    "print_shape_and_total_memory(y, 'y:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка производительности модели\n",
    "1. Оценка производительности модели через KFold кросс-валидацию при сочетании  \n",
    "параметров: \n",
    "\n",
    "    Структура слоев:  \n",
    "    - [512, 512, 512]  \n",
    "    - [1024, 512, 1024]  \n",
    "    - [512, 256, 512]  \n",
    "\n",
    "    Набор dropout:   \n",
    "    - {0.1, 0.3, 0.5}\n",
    "\n",
    "2. Повторяем эксперименты 15 и 17 с параметрами EarlyStopping   \n",
    "('min_delta': 0.005, 'patience': 20`)  \n",
    "15\tdt2023_10Aug22_29_10 None [1024, 512, 1024]\tEarlyStopping\t0.1\t0.41 0.01  \n",
    "17\tdt2023_11Aug00_25_08 None [1024, 512, 1024]\tEarlyStopping\t0.5\t0.40 0.00\n",
    "\n",
    "3. Добавляем еще слой:\n",
    "    - [512, 1024, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "21/21 [==============================] - 12s 507ms/step - loss: 0.2189 - binary_accuracy: 0.9293 - val_loss: 0.5741 - val_binary_accuracy: 0.9848\n",
      "Epoch 2/150\n",
      "21/21 [==============================] - 10s 493ms/step - loss: 0.0839 - binary_accuracy: 0.9792 - val_loss: 0.5458 - val_binary_accuracy: 0.9849\n",
      "Epoch 3/150\n",
      "21/21 [==============================] - 10s 483ms/step - loss: 0.0789 - binary_accuracy: 0.9794 - val_loss: 0.5327 - val_binary_accuracy: 0.9848\n",
      "Epoch 4/150\n",
      "21/21 [==============================] - 10s 483ms/step - loss: 0.0770 - binary_accuracy: 0.9796 - val_loss: 0.5122 - val_binary_accuracy: 0.9845\n",
      "Epoch 5/150\n",
      "21/21 [==============================] - 10s 493ms/step - loss: 0.0741 - binary_accuracy: 0.9798 - val_loss: 0.4932 - val_binary_accuracy: 0.9848\n",
      "Epoch 6/150\n",
      "21/21 [==============================] - 10s 495ms/step - loss: 0.0715 - binary_accuracy: 0.9799 - val_loss: 0.4676 - val_binary_accuracy: 0.9848\n",
      "Epoch 7/150\n",
      "21/21 [==============================] - 10s 492ms/step - loss: 0.0697 - binary_accuracy: 0.9800 - val_loss: 0.4433 - val_binary_accuracy: 0.9848\n",
      "Epoch 8/150\n",
      "21/21 [==============================] - 10s 491ms/step - loss: 0.0682 - binary_accuracy: 0.9801 - val_loss: 0.4223 - val_binary_accuracy: 0.9849\n",
      "Epoch 9/150\n",
      "21/21 [==============================] - 10s 492ms/step - loss: 0.0670 - binary_accuracy: 0.9802 - val_loss: 0.3990 - val_binary_accuracy: 0.9849\n",
      "Epoch 10/150\n",
      "21/21 [==============================] - 10s 499ms/step - loss: 0.0660 - binary_accuracy: 0.9803 - val_loss: 0.3756 - val_binary_accuracy: 0.9848\n",
      "Epoch 11/150\n",
      "21/21 [==============================] - 10s 486ms/step - loss: 0.0650 - binary_accuracy: 0.9804 - val_loss: 0.3536 - val_binary_accuracy: 0.9849\n",
      "Epoch 12/150\n",
      "21/21 [==============================] - 10s 491ms/step - loss: 0.0643 - binary_accuracy: 0.9805 - val_loss: 0.3276 - val_binary_accuracy: 0.9850\n",
      "Epoch 13/150\n",
      "21/21 [==============================] - 10s 489ms/step - loss: 0.0635 - binary_accuracy: 0.9806 - val_loss: 0.3038 - val_binary_accuracy: 0.9850\n",
      "Epoch 14/150\n",
      "21/21 [==============================] - 11s 507ms/step - loss: 0.0629 - binary_accuracy: 0.9807 - val_loss: 0.2883 - val_binary_accuracy: 0.9847\n",
      "Epoch 15/150\n",
      "21/21 [==============================] - 10s 489ms/step - loss: 0.0623 - binary_accuracy: 0.9807 - val_loss: 0.2620 - val_binary_accuracy: 0.9850\n",
      "Epoch 16/150\n",
      "21/21 [==============================] - 10s 494ms/step - loss: 0.0617 - binary_accuracy: 0.9808 - val_loss: 0.2333 - val_binary_accuracy: 0.9851\n",
      "Epoch 17/150\n",
      "21/21 [==============================] - 10s 487ms/step - loss: 0.0612 - binary_accuracy: 0.9809 - val_loss: 0.2160 - val_binary_accuracy: 0.9850\n",
      "Epoch 18/150\n",
      "21/21 [==============================] - 10s 486ms/step - loss: 0.0607 - binary_accuracy: 0.9810 - val_loss: 0.2009 - val_binary_accuracy: 0.9845\n",
      "Epoch 19/150\n",
      "21/21 [==============================] - 10s 487ms/step - loss: 0.0603 - binary_accuracy: 0.9810 - val_loss: 0.1721 - val_binary_accuracy: 0.9851\n",
      "Epoch 20/150\n",
      "21/21 [==============================] - 10s 496ms/step - loss: 0.0598 - binary_accuracy: 0.9811 - val_loss: 0.1575 - val_binary_accuracy: 0.9851\n",
      "Epoch 21/150\n",
      "21/21 [==============================] - 10s 489ms/step - loss: 0.0593 - binary_accuracy: 0.9812 - val_loss: 0.1456 - val_binary_accuracy: 0.9847\n",
      "Epoch 22/150\n",
      "21/21 [==============================] - 10s 488ms/step - loss: 0.0589 - binary_accuracy: 0.9812 - val_loss: 0.1213 - val_binary_accuracy: 0.9852\n",
      "Epoch 23/150\n",
      "21/21 [==============================] - 10s 496ms/step - loss: 0.0585 - binary_accuracy: 0.9813 - val_loss: 0.1081 - val_binary_accuracy: 0.9853\n",
      "Epoch 24/150\n",
      "21/21 [==============================] - 10s 490ms/step - loss: 0.0581 - binary_accuracy: 0.9814 - val_loss: 0.0968 - val_binary_accuracy: 0.9853\n",
      "Epoch 25/150\n",
      "21/21 [==============================] - 10s 485ms/step - loss: 0.0578 - binary_accuracy: 0.9814 - val_loss: 0.0865 - val_binary_accuracy: 0.9852\n",
      "Epoch 26/150\n",
      "21/21 [==============================] - 10s 480ms/step - loss: 0.0574 - binary_accuracy: 0.9815 - val_loss: 0.0792 - val_binary_accuracy: 0.9851\n",
      "Epoch 27/150\n",
      "21/21 [==============================] - 10s 483ms/step - loss: 0.0570 - binary_accuracy: 0.9816 - val_loss: 0.0734 - val_binary_accuracy: 0.9850\n",
      "Epoch 28/150\n",
      "21/21 [==============================] - 10s 487ms/step - loss: 0.0567 - binary_accuracy: 0.9816 - val_loss: 0.0669 - val_binary_accuracy: 0.9854\n",
      "Epoch 29/150\n",
      "21/21 [==============================] - 10s 490ms/step - loss: 0.0562 - binary_accuracy: 0.9817 - val_loss: 0.0613 - val_binary_accuracy: 0.9856\n",
      "Epoch 30/150\n",
      "21/21 [==============================] - 10s 491ms/step - loss: 0.0560 - binary_accuracy: 0.9818 - val_loss: 0.0592 - val_binary_accuracy: 0.9854\n",
      "Epoch 31/150\n",
      "21/21 [==============================] - 10s 494ms/step - loss: 0.0556 - binary_accuracy: 0.9818 - val_loss: 0.0571 - val_binary_accuracy: 0.9853\n",
      "Epoch 32/150\n",
      "21/21 [==============================] - 10s 485ms/step - loss: 0.0554 - binary_accuracy: 0.9819 - val_loss: 0.0533 - val_binary_accuracy: 0.9855\n",
      "Epoch 33/150\n",
      "21/21 [==============================] - 10s 493ms/step - loss: 0.0550 - binary_accuracy: 0.9820 - val_loss: 0.0502 - val_binary_accuracy: 0.9858\n",
      "Epoch 34/150\n",
      "21/21 [==============================] - 10s 487ms/step - loss: 0.0548 - binary_accuracy: 0.9820 - val_loss: 0.0513 - val_binary_accuracy: 0.9854\n",
      "Epoch 35/150\n",
      "21/21 [==============================] - 10s 490ms/step - loss: 0.0544 - binary_accuracy: 0.9821 - val_loss: 0.0486 - val_binary_accuracy: 0.9858\n",
      "Epoch 36/150\n",
      "21/21 [==============================] - 10s 487ms/step - loss: 0.0541 - binary_accuracy: 0.9822 - val_loss: 0.0487 - val_binary_accuracy: 0.9856\n",
      "Epoch 37/150\n",
      "21/21 [==============================] - 10s 498ms/step - loss: 0.0538 - binary_accuracy: 0.9822 - val_loss: 0.0471 - val_binary_accuracy: 0.9858\n",
      "Epoch 38/150\n",
      "21/21 [==============================] - 10s 489ms/step - loss: 0.0535 - binary_accuracy: 0.9823 - val_loss: 0.0469 - val_binary_accuracy: 0.9859\n",
      "Epoch 39/150\n",
      "21/21 [==============================] - 10s 490ms/step - loss: 0.0533 - binary_accuracy: 0.9823 - val_loss: 0.0466 - val_binary_accuracy: 0.9859\n",
      "Epoch 40/150\n",
      "21/21 [==============================] - 10s 484ms/step - loss: 0.0530 - binary_accuracy: 0.9824 - val_loss: 0.0457 - val_binary_accuracy: 0.9861\n",
      "Epoch 41/150\n",
      "21/21 [==============================] - 10s 485ms/step - loss: 0.0527 - binary_accuracy: 0.9825 - val_loss: 0.0457 - val_binary_accuracy: 0.9860\n",
      "Epoch 42/150\n",
      "21/21 [==============================] - 10s 494ms/step - loss: 0.0526 - binary_accuracy: 0.9825 - val_loss: 0.0466 - val_binary_accuracy: 0.9856\n",
      "Epoch 43/150\n",
      "21/21 [==============================] - 10s 493ms/step - loss: 0.0523 - binary_accuracy: 0.9826 - val_loss: 0.0459 - val_binary_accuracy: 0.9859\n",
      "890/890 [==============================] - 4s 4ms/step\n",
      "Epoch 1/150\n",
      "21/21 [==============================] - 12s 501ms/step - loss: 0.2217 - binary_accuracy: 0.9280 - val_loss: 0.5680 - val_binary_accuracy: 0.9848\n",
      "Epoch 2/150\n",
      "21/21 [==============================] - 11s 506ms/step - loss: 0.0841 - binary_accuracy: 0.9792 - val_loss: 0.5410 - val_binary_accuracy: 0.9848\n",
      "Epoch 3/150\n",
      "21/21 [==============================] - 10s 494ms/step - loss: 0.0791 - binary_accuracy: 0.9794 - val_loss: 0.5282 - val_binary_accuracy: 0.9847\n",
      "Epoch 4/150\n",
      "21/21 [==============================] - 10s 490ms/step - loss: 0.0769 - binary_accuracy: 0.9796 - val_loss: 0.5079 - val_binary_accuracy: 0.9844\n",
      "Epoch 5/150\n",
      "21/21 [==============================] - 10s 491ms/step - loss: 0.0742 - binary_accuracy: 0.9797 - val_loss: 0.4896 - val_binary_accuracy: 0.9845\n",
      "Epoch 6/150\n",
      "21/21 [==============================] - 10s 486ms/step - loss: 0.0717 - binary_accuracy: 0.9799 - val_loss: 0.4677 - val_binary_accuracy: 0.9846\n",
      "Epoch 7/150\n",
      "21/21 [==============================] - 10s 482ms/step - loss: 0.0698 - binary_accuracy: 0.9800 - val_loss: 0.4457 - val_binary_accuracy: 0.9847\n",
      "Epoch 8/150\n",
      "21/21 [==============================] - 10s 489ms/step - loss: 0.0685 - binary_accuracy: 0.9801 - val_loss: 0.4198 - val_binary_accuracy: 0.9847\n",
      "Epoch 9/150\n",
      "21/21 [==============================] - 10s 488ms/step - loss: 0.0673 - binary_accuracy: 0.9802 - val_loss: 0.3934 - val_binary_accuracy: 0.9848\n",
      "Epoch 10/150\n",
      "21/21 [==============================] - 10s 480ms/step - loss: 0.0663 - binary_accuracy: 0.9803 - val_loss: 0.3753 - val_binary_accuracy: 0.9849\n",
      "Epoch 11/150\n",
      "21/21 [==============================] - 10s 491ms/step - loss: 0.0653 - binary_accuracy: 0.9804 - val_loss: 0.3487 - val_binary_accuracy: 0.9849\n",
      "Epoch 12/150\n",
      "21/21 [==============================] - 10s 496ms/step - loss: 0.0645 - binary_accuracy: 0.9805 - val_loss: 0.3238 - val_binary_accuracy: 0.9849\n",
      "Epoch 13/150\n",
      "21/21 [==============================] - 10s 494ms/step - loss: 0.0638 - binary_accuracy: 0.9805 - val_loss: 0.3074 - val_binary_accuracy: 0.9848\n",
      "Epoch 14/150\n",
      "21/21 [==============================] - 11s 508ms/step - loss: 0.0632 - binary_accuracy: 0.9806 - val_loss: 0.2804 - val_binary_accuracy: 0.9848\n",
      "Epoch 15/150\n",
      "21/21 [==============================] - 10s 477ms/step - loss: 0.0626 - binary_accuracy: 0.9807 - val_loss: 0.2586 - val_binary_accuracy: 0.9848\n",
      "Epoch 16/150\n",
      "21/21 [==============================] - 10s 483ms/step - loss: 0.0621 - binary_accuracy: 0.9807 - val_loss: 0.2332 - val_binary_accuracy: 0.9851\n",
      "Epoch 17/150\n",
      "21/21 [==============================] - 10s 486ms/step - loss: 0.0616 - binary_accuracy: 0.9808 - val_loss: 0.2158 - val_binary_accuracy: 0.9849\n",
      "Epoch 18/150\n",
      "21/21 [==============================] - 10s 478ms/step - loss: 0.0611 - binary_accuracy: 0.9809 - val_loss: 0.1991 - val_binary_accuracy: 0.9848\n",
      "Epoch 19/150\n",
      "21/21 [==============================] - 10s 491ms/step - loss: 0.0606 - binary_accuracy: 0.9809 - val_loss: 0.1747 - val_binary_accuracy: 0.9850\n",
      "Epoch 20/150\n",
      "21/21 [==============================] - 10s 486ms/step - loss: 0.0602 - binary_accuracy: 0.9810 - val_loss: 0.1567 - val_binary_accuracy: 0.9850\n",
      "Epoch 21/150\n",
      "21/21 [==============================] - 10s 498ms/step - loss: 0.0598 - binary_accuracy: 0.9811 - val_loss: 0.1397 - val_binary_accuracy: 0.9850\n",
      "Epoch 22/150\n",
      "21/21 [==============================] - 10s 486ms/step - loss: 0.0593 - binary_accuracy: 0.9811 - val_loss: 0.1254 - val_binary_accuracy: 0.9850\n",
      "Epoch 23/150\n",
      "21/21 [==============================] - 11s 511ms/step - loss: 0.0590 - binary_accuracy: 0.9812 - val_loss: 0.1131 - val_binary_accuracy: 0.9850\n",
      "Epoch 24/150\n",
      "21/21 [==============================] - 10s 495ms/step - loss: 0.0585 - binary_accuracy: 0.9813 - val_loss: 0.0983 - val_binary_accuracy: 0.9852\n",
      "Epoch 25/150\n",
      "21/21 [==============================] - 11s 502ms/step - loss: 0.0582 - binary_accuracy: 0.9813 - val_loss: 0.0873 - val_binary_accuracy: 0.9852\n",
      "Epoch 26/150\n",
      "21/21 [==============================] - 11s 522ms/step - loss: 0.0577 - binary_accuracy: 0.9814 - val_loss: 0.0797 - val_binary_accuracy: 0.9853\n",
      "Epoch 27/150\n",
      "21/21 [==============================] - 10s 491ms/step - loss: 0.0574 - binary_accuracy: 0.9815 - val_loss: 0.0742 - val_binary_accuracy: 0.9852\n",
      "Epoch 28/150\n",
      "21/21 [==============================] - 10s 486ms/step - loss: 0.0571 - binary_accuracy: 0.9815 - val_loss: 0.0685 - val_binary_accuracy: 0.9852\n",
      "Epoch 29/150\n",
      "21/21 [==============================] - 10s 491ms/step - loss: 0.0567 - binary_accuracy: 0.9816 - val_loss: 0.0619 - val_binary_accuracy: 0.9855\n",
      "Epoch 30/150\n",
      "21/21 [==============================] - 10s 491ms/step - loss: 0.0563 - binary_accuracy: 0.9817 - val_loss: 0.0587 - val_binary_accuracy: 0.9854\n",
      "Epoch 31/150\n",
      "21/21 [==============================] - 10s 491ms/step - loss: 0.0560 - binary_accuracy: 0.9817 - val_loss: 0.0577 - val_binary_accuracy: 0.9852\n",
      "Epoch 32/150\n",
      "21/21 [==============================] - 10s 495ms/step - loss: 0.0557 - binary_accuracy: 0.9818 - val_loss: 0.0533 - val_binary_accuracy: 0.9855\n",
      "Epoch 33/150\n",
      "21/21 [==============================] - 11s 502ms/step - loss: 0.0554 - binary_accuracy: 0.9819 - val_loss: 0.0515 - val_binary_accuracy: 0.9856\n",
      "Epoch 34/150\n",
      "21/21 [==============================] - 10s 492ms/step - loss: 0.0551 - binary_accuracy: 0.9819 - val_loss: 0.0508 - val_binary_accuracy: 0.9855\n",
      "Epoch 35/150\n",
      "21/21 [==============================] - 11s 507ms/step - loss: 0.0548 - binary_accuracy: 0.9820 - val_loss: 0.0493 - val_binary_accuracy: 0.9856\n",
      "Epoch 36/150\n",
      "21/21 [==============================] - 10s 499ms/step - loss: 0.0544 - binary_accuracy: 0.9821 - val_loss: 0.0482 - val_binary_accuracy: 0.9858\n",
      "Epoch 37/150\n",
      "21/21 [==============================] - 10s 492ms/step - loss: 0.0542 - binary_accuracy: 0.9821 - val_loss: 0.0477 - val_binary_accuracy: 0.9858\n",
      "Epoch 38/150\n",
      "21/21 [==============================] - 10s 490ms/step - loss: 0.0539 - binary_accuracy: 0.9822 - val_loss: 0.0476 - val_binary_accuracy: 0.9856\n",
      "Epoch 39/150\n",
      "21/21 [==============================] - 10s 502ms/step - loss: 0.0536 - binary_accuracy: 0.9822 - val_loss: 0.0466 - val_binary_accuracy: 0.9858\n",
      "Epoch 40/150\n",
      "21/21 [==============================] - 11s 502ms/step - loss: 0.0533 - binary_accuracy: 0.9823 - val_loss: 0.0470 - val_binary_accuracy: 0.9857\n",
      "Epoch 41/150\n",
      "21/21 [==============================] - 11s 509ms/step - loss: 0.0530 - binary_accuracy: 0.9824 - val_loss: 0.0456 - val_binary_accuracy: 0.9861\n",
      "Epoch 42/150\n",
      "21/21 [==============================] - 10s 497ms/step - loss: 0.0529 - binary_accuracy: 0.9824 - val_loss: 0.0473 - val_binary_accuracy: 0.9856\n",
      "Epoch 43/150\n",
      "21/21 [==============================] - 10s 498ms/step - loss: 0.0526 - binary_accuracy: 0.9825 - val_loss: 0.0453 - val_binary_accuracy: 0.9861\n",
      "890/890 [==============================] - 4s 4ms/step\n",
      "Epoch 1/150\n",
      "21/21 [==============================] - 12s 481ms/step - loss: 0.2163 - binary_accuracy: 0.9297 - val_loss: 0.5739 - val_binary_accuracy: 0.9845\n",
      "Epoch 2/150\n",
      "21/21 [==============================] - 10s 485ms/step - loss: 0.0839 - binary_accuracy: 0.9792 - val_loss: 0.5425 - val_binary_accuracy: 0.9847\n",
      "Epoch 3/150\n",
      "21/21 [==============================] - 10s 480ms/step - loss: 0.0790 - binary_accuracy: 0.9794 - val_loss: 0.5324 - val_binary_accuracy: 0.9847\n",
      "Epoch 4/150\n",
      "21/21 [==============================] - 10s 490ms/step - loss: 0.0769 - binary_accuracy: 0.9796 - val_loss: 0.5127 - val_binary_accuracy: 0.9844\n",
      "Epoch 5/150\n",
      "21/21 [==============================] - 10s 479ms/step - loss: 0.0740 - binary_accuracy: 0.9798 - val_loss: 0.4910 - val_binary_accuracy: 0.9846\n",
      "Epoch 6/150\n",
      "21/21 [==============================] - 10s 479ms/step - loss: 0.0715 - binary_accuracy: 0.9799 - val_loss: 0.4687 - val_binary_accuracy: 0.9847\n",
      "Epoch 7/150\n",
      "21/21 [==============================] - 10s 483ms/step - loss: 0.0696 - binary_accuracy: 0.9800 - val_loss: 0.4464 - val_binary_accuracy: 0.9847\n",
      "Epoch 8/150\n",
      "21/21 [==============================] - 10s 481ms/step - loss: 0.0682 - binary_accuracy: 0.9801 - val_loss: 0.4197 - val_binary_accuracy: 0.9848\n",
      "Epoch 9/150\n",
      "21/21 [==============================] - 10s 489ms/step - loss: 0.0670 - binary_accuracy: 0.9802 - val_loss: 0.4004 - val_binary_accuracy: 0.9847\n",
      "Epoch 10/150\n",
      "21/21 [==============================] - 10s 484ms/step - loss: 0.0660 - binary_accuracy: 0.9803 - val_loss: 0.3748 - val_binary_accuracy: 0.9848\n",
      "Epoch 11/150\n",
      "21/21 [==============================] - 10s 496ms/step - loss: 0.0651 - binary_accuracy: 0.9804 - val_loss: 0.3509 - val_binary_accuracy: 0.9848\n",
      "Epoch 12/150\n",
      "21/21 [==============================] - 10s 489ms/step - loss: 0.0643 - binary_accuracy: 0.9805 - val_loss: 0.3284 - val_binary_accuracy: 0.9847\n",
      "Epoch 13/150\n",
      "21/21 [==============================] - 10s 486ms/step - loss: 0.0636 - binary_accuracy: 0.9805 - val_loss: 0.3064 - val_binary_accuracy: 0.9848\n",
      "Epoch 14/150\n",
      "21/21 [==============================] - 10s 483ms/step - loss: 0.0630 - binary_accuracy: 0.9806 - val_loss: 0.2807 - val_binary_accuracy: 0.9849\n",
      "Epoch 15/150\n",
      "21/21 [==============================] - 10s 478ms/step - loss: 0.0625 - binary_accuracy: 0.9807 - val_loss: 0.2622 - val_binary_accuracy: 0.9849\n",
      "Epoch 16/150\n",
      "21/21 [==============================] - 10s 472ms/step - loss: 0.0619 - binary_accuracy: 0.9808 - val_loss: 0.2388 - val_binary_accuracy: 0.9848\n",
      "Epoch 17/150\n",
      "21/21 [==============================] - 10s 481ms/step - loss: 0.0614 - binary_accuracy: 0.9808 - val_loss: 0.2197 - val_binary_accuracy: 0.9847\n",
      "Epoch 18/150\n",
      "21/21 [==============================] - 10s 484ms/step - loss: 0.0609 - binary_accuracy: 0.9809 - val_loss: 0.1990 - val_binary_accuracy: 0.9847\n",
      "Epoch 19/150\n",
      "21/21 [==============================] - 10s 482ms/step - loss: 0.0604 - binary_accuracy: 0.9810 - val_loss: 0.1771 - val_binary_accuracy: 0.9848\n",
      "Epoch 20/150\n",
      "21/21 [==============================] - 10s 485ms/step - loss: 0.0600 - binary_accuracy: 0.9810 - val_loss: 0.1588 - val_binary_accuracy: 0.9847\n",
      "Epoch 21/150\n",
      "21/21 [==============================] - 10s 494ms/step - loss: 0.0596 - binary_accuracy: 0.9811 - val_loss: 0.1420 - val_binary_accuracy: 0.9847\n",
      "Epoch 22/150\n",
      "21/21 [==============================] - 10s 490ms/step - loss: 0.0591 - binary_accuracy: 0.9812 - val_loss: 0.1291 - val_binary_accuracy: 0.9845\n",
      "Epoch 23/150\n",
      "21/21 [==============================] - 10s 484ms/step - loss: 0.0587 - binary_accuracy: 0.9813 - val_loss: 0.1138 - val_binary_accuracy: 0.9845\n",
      "Epoch 24/150\n",
      "21/21 [==============================] - 10s 485ms/step - loss: 0.0583 - binary_accuracy: 0.9813 - val_loss: 0.1025 - val_binary_accuracy: 0.9849\n",
      "Epoch 25/150\n",
      "21/21 [==============================] - 10s 485ms/step - loss: 0.0579 - binary_accuracy: 0.9814 - val_loss: 0.0882 - val_binary_accuracy: 0.9849\n",
      "Epoch 26/150\n",
      "21/21 [==============================] - 10s 487ms/step - loss: 0.0575 - binary_accuracy: 0.9814 - val_loss: 0.0798 - val_binary_accuracy: 0.9851\n",
      "Epoch 27/150\n",
      "21/21 [==============================] - 10s 490ms/step - loss: 0.0571 - binary_accuracy: 0.9815 - val_loss: 0.0752 - val_binary_accuracy: 0.9850\n",
      "Epoch 28/150\n",
      "21/21 [==============================] - 10s 479ms/step - loss: 0.0568 - binary_accuracy: 0.9816 - val_loss: 0.0675 - val_binary_accuracy: 0.9853\n",
      "Epoch 29/150\n",
      "21/21 [==============================] - 10s 478ms/step - loss: 0.0565 - binary_accuracy: 0.9816 - val_loss: 0.0621 - val_binary_accuracy: 0.9854\n",
      "Epoch 30/150\n",
      "21/21 [==============================] - 10s 483ms/step - loss: 0.0562 - binary_accuracy: 0.9817 - val_loss: 0.0581 - val_binary_accuracy: 0.9855\n",
      "Epoch 31/150\n",
      "21/21 [==============================] - 10s 494ms/step - loss: 0.0558 - binary_accuracy: 0.9818 - val_loss: 0.0559 - val_binary_accuracy: 0.9854\n",
      "Epoch 32/150\n",
      "21/21 [==============================] - 10s 493ms/step - loss: 0.0554 - binary_accuracy: 0.9819 - val_loss: 0.0548 - val_binary_accuracy: 0.9854\n",
      "Epoch 33/150\n",
      "21/21 [==============================] - 10s 486ms/step - loss: 0.0552 - binary_accuracy: 0.9819 - val_loss: 0.0519 - val_binary_accuracy: 0.9855\n",
      "Epoch 34/150\n",
      "21/21 [==============================] - 10s 488ms/step - loss: 0.0548 - binary_accuracy: 0.9820 - val_loss: 0.0518 - val_binary_accuracy: 0.9851\n",
      "Epoch 35/150\n",
      "21/21 [==============================] - 10s 486ms/step - loss: 0.0545 - binary_accuracy: 0.9820 - val_loss: 0.0500 - val_binary_accuracy: 0.9855\n",
      "Epoch 36/150\n",
      "21/21 [==============================] - 10s 484ms/step - loss: 0.0543 - binary_accuracy: 0.9821 - val_loss: 0.0488 - val_binary_accuracy: 0.9855\n",
      "Epoch 37/150\n",
      "21/21 [==============================] - 10s 482ms/step - loss: 0.0539 - binary_accuracy: 0.9822 - val_loss: 0.0489 - val_binary_accuracy: 0.9854\n",
      "Epoch 38/150\n",
      "21/21 [==============================] - 10s 485ms/step - loss: 0.0537 - binary_accuracy: 0.9822 - val_loss: 0.0482 - val_binary_accuracy: 0.9855\n",
      "Epoch 39/150\n",
      "21/21 [==============================] - 10s 485ms/step - loss: 0.0535 - binary_accuracy: 0.9823 - val_loss: 0.0466 - val_binary_accuracy: 0.9859\n",
      "Epoch 40/150\n",
      "21/21 [==============================] - 10s 478ms/step - loss: 0.0531 - binary_accuracy: 0.9824 - val_loss: 0.0488 - val_binary_accuracy: 0.9853\n",
      "Epoch 41/150\n",
      "21/21 [==============================] - 10s 479ms/step - loss: 0.0529 - binary_accuracy: 0.9824 - val_loss: 0.0468 - val_binary_accuracy: 0.9857\n",
      "Epoch 42/150\n",
      "21/21 [==============================] - 10s 477ms/step - loss: 0.0526 - binary_accuracy: 0.9825 - val_loss: 0.0472 - val_binary_accuracy: 0.9854\n",
      "Epoch 43/150\n",
      "21/21 [==============================] - 10s 483ms/step - loss: 0.0523 - binary_accuracy: 0.9825 - val_loss: 0.0462 - val_binary_accuracy: 0.9858\n",
      "890/890 [==============================] - 4s 4ms/step\n",
      "Epoch 1/150\n",
      "21/21 [==============================] - 12s 492ms/step - loss: 0.2172 - binary_accuracy: 0.9302 - val_loss: 0.5707 - val_binary_accuracy: 0.9848\n",
      "Epoch 2/150\n",
      "21/21 [==============================] - 10s 482ms/step - loss: 0.0839 - binary_accuracy: 0.9793 - val_loss: 0.5438 - val_binary_accuracy: 0.9849\n",
      "Epoch 3/150\n",
      "21/21 [==============================] - 10s 483ms/step - loss: 0.0790 - binary_accuracy: 0.9794 - val_loss: 0.5321 - val_binary_accuracy: 0.9848\n",
      "Epoch 4/150\n",
      "21/21 [==============================] - 10s 486ms/step - loss: 0.0770 - binary_accuracy: 0.9796 - val_loss: 0.5117 - val_binary_accuracy: 0.9846\n",
      "Epoch 5/150\n",
      "21/21 [==============================] - 10s 484ms/step - loss: 0.0742 - binary_accuracy: 0.9798 - val_loss: 0.4925 - val_binary_accuracy: 0.9846\n",
      "Epoch 6/150\n",
      "21/21 [==============================] - 10s 482ms/step - loss: 0.0716 - binary_accuracy: 0.9799 - val_loss: 0.4702 - val_binary_accuracy: 0.9847\n",
      "Epoch 7/150\n",
      "21/21 [==============================] - 10s 490ms/step - loss: 0.0698 - binary_accuracy: 0.9800 - val_loss: 0.4464 - val_binary_accuracy: 0.9848\n",
      "Epoch 8/150\n",
      "21/21 [==============================] - 10s 490ms/step - loss: 0.0684 - binary_accuracy: 0.9801 - val_loss: 0.4192 - val_binary_accuracy: 0.9849\n",
      "Epoch 9/150\n",
      "21/21 [==============================] - 10s 489ms/step - loss: 0.0674 - binary_accuracy: 0.9802 - val_loss: 0.4026 - val_binary_accuracy: 0.9848\n",
      "Epoch 10/150\n",
      "21/21 [==============================] - 10s 490ms/step - loss: 0.0664 - binary_accuracy: 0.9803 - val_loss: 0.3741 - val_binary_accuracy: 0.9849\n",
      "Epoch 11/150\n",
      "21/21 [==============================] - 10s 482ms/step - loss: 0.0654 - binary_accuracy: 0.9804 - val_loss: 0.3519 - val_binary_accuracy: 0.9850\n",
      "Epoch 12/150\n",
      "21/21 [==============================] - 10s 486ms/step - loss: 0.0646 - binary_accuracy: 0.9805 - val_loss: 0.3275 - val_binary_accuracy: 0.9850\n",
      "Epoch 13/150\n",
      "21/21 [==============================] - 10s 487ms/step - loss: 0.0639 - binary_accuracy: 0.9805 - val_loss: 0.3017 - val_binary_accuracy: 0.9851\n",
      "Epoch 14/150\n",
      "21/21 [==============================] - 10s 490ms/step - loss: 0.0633 - binary_accuracy: 0.9806 - val_loss: 0.2819 - val_binary_accuracy: 0.9850\n",
      "Epoch 15/150\n",
      "21/21 [==============================] - 10s 483ms/step - loss: 0.0627 - binary_accuracy: 0.9807 - val_loss: 0.2604 - val_binary_accuracy: 0.9849\n",
      "Epoch 16/150\n",
      "21/21 [==============================] - 10s 486ms/step - loss: 0.0622 - binary_accuracy: 0.9807 - val_loss: 0.2366 - val_binary_accuracy: 0.9849\n",
      "Epoch 17/150\n",
      "21/21 [==============================] - 10s 488ms/step - loss: 0.0617 - binary_accuracy: 0.9808 - val_loss: 0.2176 - val_binary_accuracy: 0.9848\n",
      "Epoch 18/150\n",
      "21/21 [==============================] - 10s 480ms/step - loss: 0.0611 - binary_accuracy: 0.9809 - val_loss: 0.1984 - val_binary_accuracy: 0.9848\n",
      "Epoch 19/150\n",
      "21/21 [==============================] - 10s 487ms/step - loss: 0.0607 - binary_accuracy: 0.9809 - val_loss: 0.1807 - val_binary_accuracy: 0.9848\n",
      "Epoch 20/150\n",
      "21/21 [==============================] - 10s 488ms/step - loss: 0.0602 - binary_accuracy: 0.9810 - val_loss: 0.1604 - val_binary_accuracy: 0.9848\n",
      "Epoch 21/150\n",
      "21/21 [==============================] - 10s 487ms/step - loss: 0.0598 - binary_accuracy: 0.9811 - val_loss: 0.1446 - val_binary_accuracy: 0.9848\n",
      "Epoch 22/150\n",
      "21/21 [==============================] - 10s 483ms/step - loss: 0.0594 - binary_accuracy: 0.9811 - val_loss: 0.1251 - val_binary_accuracy: 0.9851\n",
      "Epoch 23/150\n",
      "21/21 [==============================] - 10s 485ms/step - loss: 0.0589 - binary_accuracy: 0.9812 - val_loss: 0.1140 - val_binary_accuracy: 0.9850\n",
      "Epoch 24/150\n",
      "21/21 [==============================] - 10s 489ms/step - loss: 0.0586 - binary_accuracy: 0.9812 - val_loss: 0.1006 - val_binary_accuracy: 0.9850\n",
      "Epoch 25/150\n",
      "21/21 [==============================] - 10s 485ms/step - loss: 0.0582 - binary_accuracy: 0.9813 - val_loss: 0.0902 - val_binary_accuracy: 0.9851\n",
      "Epoch 26/150\n",
      "21/21 [==============================] - 10s 484ms/step - loss: 0.0578 - binary_accuracy: 0.9814 - val_loss: 0.0829 - val_binary_accuracy: 0.9850\n",
      "Epoch 27/150\n",
      "21/21 [==============================] - 10s 491ms/step - loss: 0.0574 - binary_accuracy: 0.9815 - val_loss: 0.0741 - val_binary_accuracy: 0.9852\n",
      "Epoch 28/150\n",
      "21/21 [==============================] - 10s 484ms/step - loss: 0.0570 - binary_accuracy: 0.9815 - val_loss: 0.0690 - val_binary_accuracy: 0.9852\n",
      "Epoch 29/150\n",
      "21/21 [==============================] - 10s 480ms/step - loss: 0.0567 - binary_accuracy: 0.9816 - val_loss: 0.0654 - val_binary_accuracy: 0.9852\n",
      "Epoch 30/150\n",
      "21/21 [==============================] - 10s 488ms/step - loss: 0.0564 - binary_accuracy: 0.9817 - val_loss: 0.0594 - val_binary_accuracy: 0.9854\n",
      "Epoch 31/150\n",
      "21/21 [==============================] - 10s 471ms/step - loss: 0.0561 - binary_accuracy: 0.9817 - val_loss: 0.0549 - val_binary_accuracy: 0.9855\n",
      "Epoch 32/150\n",
      "21/21 [==============================] - 10s 484ms/step - loss: 0.0557 - binary_accuracy: 0.9818 - val_loss: 0.0544 - val_binary_accuracy: 0.9853\n",
      "Epoch 33/150\n",
      "21/21 [==============================] - 10s 495ms/step - loss: 0.0554 - binary_accuracy: 0.9819 - val_loss: 0.0513 - val_binary_accuracy: 0.9856\n",
      "Epoch 34/150\n",
      "21/21 [==============================] - 10s 487ms/step - loss: 0.0551 - binary_accuracy: 0.9819 - val_loss: 0.0499 - val_binary_accuracy: 0.9857\n",
      "Epoch 35/150\n",
      "21/21 [==============================] - 10s 485ms/step - loss: 0.0547 - binary_accuracy: 0.9820 - val_loss: 0.0489 - val_binary_accuracy: 0.9856\n",
      "Epoch 36/150\n",
      "21/21 [==============================] - 10s 483ms/step - loss: 0.0545 - binary_accuracy: 0.9820 - val_loss: 0.0488 - val_binary_accuracy: 0.9857\n",
      "Epoch 37/150\n",
      "21/21 [==============================] - 10s 489ms/step - loss: 0.0542 - binary_accuracy: 0.9821 - val_loss: 0.0482 - val_binary_accuracy: 0.9856\n",
      "Epoch 38/150\n",
      "21/21 [==============================] - 10s 487ms/step - loss: 0.0539 - binary_accuracy: 0.9822 - val_loss: 0.0473 - val_binary_accuracy: 0.9858\n",
      "Epoch 39/150\n",
      "21/21 [==============================] - 10s 491ms/step - loss: 0.0536 - binary_accuracy: 0.9822 - val_loss: 0.0476 - val_binary_accuracy: 0.9855\n",
      "Epoch 40/150\n",
      "21/21 [==============================] - 10s 490ms/step - loss: 0.0533 - binary_accuracy: 0.9823 - val_loss: 0.0465 - val_binary_accuracy: 0.9858\n",
      "Epoch 41/150\n",
      "21/21 [==============================] - 10s 479ms/step - loss: 0.0531 - binary_accuracy: 0.9824 - val_loss: 0.0464 - val_binary_accuracy: 0.9858\n",
      "Epoch 42/150\n",
      "21/21 [==============================] - 10s 486ms/step - loss: 0.0528 - binary_accuracy: 0.9824 - val_loss: 0.0456 - val_binary_accuracy: 0.9860\n",
      "Epoch 43/150\n",
      "21/21 [==============================] - 10s 487ms/step - loss: 0.0525 - binary_accuracy: 0.9825 - val_loss: 0.0464 - val_binary_accuracy: 0.9856\n",
      "Epoch 44/150\n",
      "21/21 [==============================] - 10s 488ms/step - loss: 0.0523 - binary_accuracy: 0.9825 - val_loss: 0.0457 - val_binary_accuracy: 0.9858\n",
      "Epoch 45/150\n",
      "21/21 [==============================] - 10s 493ms/step - loss: 0.0520 - binary_accuracy: 0.9826 - val_loss: 0.0465 - val_binary_accuracy: 0.9856\n",
      "890/890 [==============================] - 4s 4ms/step\n",
      "Epoch 1/150\n",
      "21/21 [==============================] - 12s 501ms/step - loss: 0.2223 - binary_accuracy: 0.9284 - val_loss: 0.5761 - val_binary_accuracy: 0.9848\n",
      "Epoch 2/150\n",
      "21/21 [==============================] - 10s 490ms/step - loss: 0.0844 - binary_accuracy: 0.9792 - val_loss: 0.5456 - val_binary_accuracy: 0.9850\n",
      "Epoch 3/150\n",
      "21/21 [==============================] - 10s 489ms/step - loss: 0.0790 - binary_accuracy: 0.9794 - val_loss: 0.5323 - val_binary_accuracy: 0.9847\n",
      "Epoch 4/150\n",
      "21/21 [==============================] - 10s 488ms/step - loss: 0.0765 - binary_accuracy: 0.9796 - val_loss: 0.5127 - val_binary_accuracy: 0.9844\n",
      "Epoch 5/150\n",
      "21/21 [==============================] - 10s 484ms/step - loss: 0.0737 - binary_accuracy: 0.9798 - val_loss: 0.4923 - val_binary_accuracy: 0.9847\n",
      "Epoch 6/150\n",
      "21/21 [==============================] - 10s 477ms/step - loss: 0.0711 - binary_accuracy: 0.9799 - val_loss: 0.4694 - val_binary_accuracy: 0.9848\n",
      "Epoch 7/150\n",
      "21/21 [==============================] - 10s 476ms/step - loss: 0.0693 - binary_accuracy: 0.9800 - val_loss: 0.4447 - val_binary_accuracy: 0.9848\n",
      "Epoch 8/150\n",
      "21/21 [==============================] - 10s 480ms/step - loss: 0.0680 - binary_accuracy: 0.9801 - val_loss: 0.4237 - val_binary_accuracy: 0.9848\n",
      "Epoch 9/150\n",
      "21/21 [==============================] - 10s 486ms/step - loss: 0.0670 - binary_accuracy: 0.9802 - val_loss: 0.3961 - val_binary_accuracy: 0.9850\n",
      "Epoch 10/150\n",
      "21/21 [==============================] - 10s 480ms/step - loss: 0.0660 - binary_accuracy: 0.9803 - val_loss: 0.3746 - val_binary_accuracy: 0.9850\n",
      "Epoch 11/150\n",
      "21/21 [==============================] - 10s 479ms/step - loss: 0.0652 - binary_accuracy: 0.9804 - val_loss: 0.3515 - val_binary_accuracy: 0.9849\n",
      "Epoch 12/150\n",
      "21/21 [==============================] - 10s 485ms/step - loss: 0.0644 - binary_accuracy: 0.9804 - val_loss: 0.3262 - val_binary_accuracy: 0.9850\n",
      "Epoch 13/150\n",
      "21/21 [==============================] - 10s 476ms/step - loss: 0.0638 - binary_accuracy: 0.9805 - val_loss: 0.3048 - val_binary_accuracy: 0.9850\n",
      "Epoch 14/150\n",
      "21/21 [==============================] - 10s 481ms/step - loss: 0.0632 - binary_accuracy: 0.9806 - val_loss: 0.2808 - val_binary_accuracy: 0.9850\n",
      "Epoch 15/150\n",
      "21/21 [==============================] - 10s 487ms/step - loss: 0.0626 - binary_accuracy: 0.9807 - val_loss: 0.2592 - val_binary_accuracy: 0.9850\n",
      "Epoch 16/150\n",
      "21/21 [==============================] - 10s 480ms/step - loss: 0.0621 - binary_accuracy: 0.9807 - val_loss: 0.2342 - val_binary_accuracy: 0.9851\n",
      "Epoch 17/150\n",
      "21/21 [==============================] - 10s 477ms/step - loss: 0.0616 - binary_accuracy: 0.9808 - val_loss: 0.2146 - val_binary_accuracy: 0.9849\n",
      "Epoch 18/150\n",
      "21/21 [==============================] - 10s 477ms/step - loss: 0.0611 - binary_accuracy: 0.9808 - val_loss: 0.1950 - val_binary_accuracy: 0.9850\n",
      "Epoch 19/150\n",
      "21/21 [==============================] - 10s 480ms/step - loss: 0.0607 - binary_accuracy: 0.9809 - val_loss: 0.1763 - val_binary_accuracy: 0.9849\n",
      "Epoch 20/150\n",
      "21/21 [==============================] - 10s 491ms/step - loss: 0.0602 - binary_accuracy: 0.9810 - val_loss: 0.1628 - val_binary_accuracy: 0.9846\n",
      "Epoch 21/150\n",
      "21/21 [==============================] - 10s 497ms/step - loss: 0.0599 - binary_accuracy: 0.9810 - val_loss: 0.1425 - val_binary_accuracy: 0.9851\n",
      "Epoch 22/150\n",
      "21/21 [==============================] - 10s 484ms/step - loss: 0.0594 - binary_accuracy: 0.9811 - val_loss: 0.1235 - val_binary_accuracy: 0.9852\n",
      "Epoch 23/150\n",
      "21/21 [==============================] - 10s 488ms/step - loss: 0.0590 - binary_accuracy: 0.9812 - val_loss: 0.1079 - val_binary_accuracy: 0.9853\n",
      "Epoch 24/150\n",
      "21/21 [==============================] - 10s 479ms/step - loss: 0.0587 - binary_accuracy: 0.9812 - val_loss: 0.0952 - val_binary_accuracy: 0.9854\n",
      "Epoch 25/150\n",
      "21/21 [==============================] - 10s 486ms/step - loss: 0.0583 - binary_accuracy: 0.9813 - val_loss: 0.0885 - val_binary_accuracy: 0.9853\n",
      "Epoch 26/150\n",
      "21/21 [==============================] - 10s 484ms/step - loss: 0.0579 - binary_accuracy: 0.9813 - val_loss: 0.0807 - val_binary_accuracy: 0.9852\n",
      "Epoch 27/150\n",
      "21/21 [==============================] - 10s 484ms/step - loss: 0.0576 - binary_accuracy: 0.9814 - val_loss: 0.0726 - val_binary_accuracy: 0.9854\n",
      "Epoch 28/150\n",
      "21/21 [==============================] - 10s 477ms/step - loss: 0.0573 - binary_accuracy: 0.9815 - val_loss: 0.0659 - val_binary_accuracy: 0.9855\n",
      "Epoch 29/150\n",
      "21/21 [==============================] - 10s 480ms/step - loss: 0.0569 - binary_accuracy: 0.9815 - val_loss: 0.0631 - val_binary_accuracy: 0.9854\n",
      "Epoch 30/150\n",
      "21/21 [==============================] - 10s 479ms/step - loss: 0.0566 - binary_accuracy: 0.9816 - val_loss: 0.0575 - val_binary_accuracy: 0.9857\n",
      "Epoch 31/150\n",
      "21/21 [==============================] - 10s 481ms/step - loss: 0.0563 - binary_accuracy: 0.9817 - val_loss: 0.0575 - val_binary_accuracy: 0.9854\n",
      "Epoch 32/150\n",
      "21/21 [==============================] - 10s 485ms/step - loss: 0.0559 - binary_accuracy: 0.9817 - val_loss: 0.0547 - val_binary_accuracy: 0.9854\n",
      "Epoch 33/150\n",
      "21/21 [==============================] - 10s 484ms/step - loss: 0.0556 - binary_accuracy: 0.9818 - val_loss: 0.0519 - val_binary_accuracy: 0.9856\n",
      "Epoch 34/150\n",
      "21/21 [==============================] - 10s 476ms/step - loss: 0.0553 - binary_accuracy: 0.9819 - val_loss: 0.0512 - val_binary_accuracy: 0.9855\n",
      "Epoch 35/150\n",
      "21/21 [==============================] - 10s 483ms/step - loss: 0.0551 - binary_accuracy: 0.9819 - val_loss: 0.0474 - val_binary_accuracy: 0.9860\n",
      "Epoch 36/150\n",
      "21/21 [==============================] - 10s 484ms/step - loss: 0.0547 - binary_accuracy: 0.9820 - val_loss: 0.0498 - val_binary_accuracy: 0.9855\n",
      "Epoch 37/150\n",
      "21/21 [==============================] - 10s 480ms/step - loss: 0.0544 - binary_accuracy: 0.9820 - val_loss: 0.0466 - val_binary_accuracy: 0.9860\n",
      "Epoch 38/150\n",
      "21/21 [==============================] - 10s 478ms/step - loss: 0.0541 - binary_accuracy: 0.9821 - val_loss: 0.0466 - val_binary_accuracy: 0.9859\n",
      "Epoch 39/150\n",
      "21/21 [==============================] - 10s 483ms/step - loss: 0.0539 - binary_accuracy: 0.9822 - val_loss: 0.0466 - val_binary_accuracy: 0.9859\n",
      "Epoch 40/150\n",
      "21/21 [==============================] - 10s 482ms/step - loss: 0.0536 - binary_accuracy: 0.9822 - val_loss: 0.0469 - val_binary_accuracy: 0.9858\n",
      "Epoch 41/150\n",
      "21/21 [==============================] - 10s 484ms/step - loss: 0.0533 - binary_accuracy: 0.9823 - val_loss: 0.0465 - val_binary_accuracy: 0.9858\n",
      "Epoch 42/150\n",
      "21/21 [==============================] - 10s 483ms/step - loss: 0.0531 - binary_accuracy: 0.9823 - val_loss: 0.0456 - val_binary_accuracy: 0.9860\n",
      "890/890 [==============================] - 3s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "ACTIVATION = 'relu'\n",
    "BATCH_SIZE = 5000\n",
    "# Список для создания `Сallbacks` объектов. \n",
    "CALLBACKS_PARAMS: list[mu.CallbackParams] = [\n",
    "    {\n",
    "        'callback': tf.keras.callbacks.EarlyStopping,\n",
    "        'params': {\n",
    "            'monitor': 'val_loss',\n",
    "            'mode': 'min',\n",
    "            'min_delta': 0.01,\n",
    "            'patience': 10,\n",
    "            'restore_best_weights': True,\n",
    "        }\n",
    "    },\n",
    "]\n",
    "# None или результат `mu.create_callbacks(CALLBACKS_PARAMS)`\n",
    "CALLBACKS = mu.create_callbacks(CALLBACKS_PARAMS)\n",
    "DROPOUT = 0.1\n",
    "EPOCHS = 150\n",
    "KERNEL_REGULARIZER = None\n",
    "# Структура скрытых слоев в последовательной DNN.\n",
    "LAYERS_STRCT = [512, 1024, 512]\n",
    "LEARNING_RATE = 0.001\n",
    "# Число циклов с кросс-валидацией.\n",
    "N_REPEATS = 1\n",
    "# Число фолдов в кросс-валидации.\n",
    "N_SPLITS = 5\n",
    "# Список метрик, используемых для рассчета производительности модели.\n",
    "METRICS = [mu.f1_score_micro,]\n",
    "SHUFFLE = True\n",
    "VALIDATION_SPLIT = 0.1\n",
    "VERBOSE = 1\n",
    "\n",
    "\n",
    "# Формирование фабрики скомпилированных моделей.\n",
    "mfabric = mu.ModelCompileFabric(\n",
    "    activation=ACTIVATION,\n",
    "    kernel_regularizer=KERNEL_REGULARIZER,\n",
    "    dropout=DROPOUT,\n",
    "    layers_strct=LAYERS_STRCT,\n",
    "    learning_rate=LEARNING_RATE,\n",
    ")\n",
    "# Создаем прокси для обучения моделей.\n",
    "mproxy = mu.ProxyFitModel(\n",
    "    mfabric,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=CALLBACKS,\n",
    "    epochs=EPOCHS,\n",
    "    shuffle=SHUFFLE,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    verbose=VERBOSE,\n",
    ")\n",
    "random_state = random.randint(0, 10_000)\n",
    "# Оценка производительности модели через кросс-валидацию.\n",
    "results, histories = mu.evaluate_model(\n",
    "    features=x.to_numpy(),\n",
    "    lbls=y.to_numpy(),\n",
    "    metrics=METRICS,  # type: ignore\n",
    "    proxy_model=mproxy,\n",
    "    n_repeats=N_REPEATS,\n",
    "    n_splits=N_SPLITS,\n",
    "    random_state=random_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение результатов\n",
    "Сохранение результатов оценки производительности модели и сопутсвующих параметров. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл был дополнен\n"
     ]
    }
   ],
   "source": [
    "data_info_dict = {\n",
    "    'file_name_features': PATH_TO_FEATURES.name,\n",
    "    'file_name_labels': PATH_TO_LABELS.name,\n",
    "}\n",
    "model_params_dict = {\n",
    "    'activation': ACTIVATION,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'callbacks': (\n",
    "        CALLBACKS if CALLBACKS is None\n",
    "        else mu.create_callbacks_info(CALLBACKS_PARAMS)\n",
    "    ),\n",
    "    'dropout': DROPOUT,\n",
    "    'epochs': EPOCHS,\n",
    "    'kernel_regularizer': KERNEL_REGULARIZER,\n",
    "    'layers_strct': LAYERS_STRCT,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'n_repeats': N_REPEATS,\n",
    "    'n_splits': N_SPLITS,\n",
    "    'random_state': random_state,\n",
    "    'shuffle': SHUFFLE,\n",
    "    'validation_split': VALIDATION_SPLIT,\n",
    "    'mean_epoch': mean_epochs(histories)\n",
    "}\n",
    "# Формируем словарь с текущей оценкой производительности модели\n",
    "# и сопутсвующими параметрами.\n",
    "model_eval_params: mu.ModelEvalParams = {\n",
    "    'data_info': data_info_dict,\n",
    "    'model_params': model_params_dict,\n",
    "    'scores': mu.get_scores_stats(results),\n",
    "}\n",
    "cur_datetime = datetime.now().strftime('%Y_%d%b%H_%M_%S')\n",
    "# Записываем результаты текущей оценки производительности модели в файл.\n",
    "eval_log_to_json(\n",
    "    log_file=DIR_ROOT / 'experiments/eval.json',\n",
    "    params={f'dt{cur_datetime}': model_eval_params},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>kernel_regularizer</th>\n",
       "      <th>layers_strct</th>\n",
       "      <th>callback</th>\n",
       "      <th>dropout</th>\n",
       "      <th>mean_epoch</th>\n",
       "      <th>mean_f1_score_micro</th>\n",
       "      <th>std_f1_score_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dt2023_10Aug11_23_28</td>\n",
       "      <td>None</td>\n",
       "      <td>[512, 512, 512]</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>dt2023_11Aug16_26_00</td>\n",
       "      <td>None</td>\n",
       "      <td>[1024, 512, 1024]</td>\n",
       "      <td>EarlyStopping</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dt2023_10Aug22_29_10</td>\n",
       "      <td>None</td>\n",
       "      <td>[1024, 512, 1024]</td>\n",
       "      <td>EarlyStopping</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>dt2023_11Aug17_55_40</td>\n",
       "      <td>None</td>\n",
       "      <td>[1024, 512, 1024]</td>\n",
       "      <td>EarlyStopping</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dt2023_11Aug00_25_08</td>\n",
       "      <td>None</td>\n",
       "      <td>[1024, 512, 1024]</td>\n",
       "      <td>EarlyStopping</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dt2023_10Aug02_48_17</td>\n",
       "      <td>None</td>\n",
       "      <td>[512, 512, 512]</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dt2023_10Aug23_27_43</td>\n",
       "      <td>None</td>\n",
       "      <td>[1024, 512, 1024]</td>\n",
       "      <td>EarlyStopping</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dt2023_10Aug02_05_30</td>\n",
       "      <td>None</td>\n",
       "      <td>[512, 512, 512]</td>\n",
       "      <td>EarlyStopping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>dt2023_13Aug20_37_12</td>\n",
       "      <td>None</td>\n",
       "      <td>[512, 1024, 512]</td>\n",
       "      <td>EarlyStopping</td>\n",
       "      <td>0.1</td>\n",
       "      <td>43.2</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>dt2023_11Aug20_02_52</td>\n",
       "      <td>None</td>\n",
       "      <td>[512, 512, 512]</td>\n",
       "      <td>EarlyStopping</td>\n",
       "      <td>0.1</td>\n",
       "      <td>43.4</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dt2023_10Aug19_52_56</td>\n",
       "      <td>None</td>\n",
       "      <td>[512, 512, 512]</td>\n",
       "      <td>EarlyStopping</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dt2023_10Aug21_26_14</td>\n",
       "      <td>None</td>\n",
       "      <td>[512, 512, 512]</td>\n",
       "      <td>EarlyStopping</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dt2023_11Aug01_41_25</td>\n",
       "      <td>None</td>\n",
       "      <td>[512, 256, 512]</td>\n",
       "      <td>EarlyStopping</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dt2023_11Aug00_59_23</td>\n",
       "      <td>None</td>\n",
       "      <td>[512, 256, 512]</td>\n",
       "      <td>EarlyStopping</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dt2023_10Aug17_30_38</td>\n",
       "      <td>None</td>\n",
       "      <td>[512, 512, 512]</td>\n",
       "      <td>EarlyStopping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dt2023_10Aug20_36_08</td>\n",
       "      <td>None</td>\n",
       "      <td>[512, 512, 512]</td>\n",
       "      <td>EarlyStopping</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dt2023_10Aug01_27_45</td>\n",
       "      <td>None</td>\n",
       "      <td>[512, 512, 512]</td>\n",
       "      <td>EarlyStopping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>dt2023_11Aug02_29_04</td>\n",
       "      <td>None</td>\n",
       "      <td>[512, 256, 512]</td>\n",
       "      <td>EarlyStopping</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dt2023_10Aug01_02_16</td>\n",
       "      <td>None</td>\n",
       "      <td>[512, 512, 512]</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dt2023_10Aug00_51_32</td>\n",
       "      <td>None</td>\n",
       "      <td>[512, 512, 512]</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dt2023_10Aug15_30_51</td>\n",
       "      <td>l1</td>\n",
       "      <td>[512, 512, 512]</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dt2023_10Aug19_06_33</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>[512, 512, 512]</td>\n",
       "      <td>EarlyStopping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dt2023_10Aug16_01_52</td>\n",
       "      <td>l1</td>\n",
       "      <td>[512, 512, 512]</td>\n",
       "      <td>EarlyStopping</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dt2023_10Aug16_56_37</td>\n",
       "      <td>l1</td>\n",
       "      <td>[512, 512, 512]</td>\n",
       "      <td>EarlyStopping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dt2023_10Aug18_05_45</td>\n",
       "      <td>l2</td>\n",
       "      <td>[512, 512, 512]</td>\n",
       "      <td>EarlyStopping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model_name kernel_regularizer       layers_strct       callback  \\\n",
       "5   dt2023_10Aug11_23_28               None    [512, 512, 512]           None   \n",
       "21  dt2023_11Aug16_26_00               None  [1024, 512, 1024]  EarlyStopping   \n",
       "15  dt2023_10Aug22_29_10               None  [1024, 512, 1024]  EarlyStopping   \n",
       "22  dt2023_11Aug17_55_40               None  [1024, 512, 1024]  EarlyStopping   \n",
       "17  dt2023_11Aug00_25_08               None  [1024, 512, 1024]  EarlyStopping   \n",
       "4   dt2023_10Aug02_48_17               None    [512, 512, 512]           None   \n",
       "16  dt2023_10Aug23_27_43               None  [1024, 512, 1024]  EarlyStopping   \n",
       "3   dt2023_10Aug02_05_30               None    [512, 512, 512]  EarlyStopping   \n",
       "24  dt2023_13Aug20_37_12               None   [512, 1024, 512]  EarlyStopping   \n",
       "23  dt2023_11Aug20_02_52               None    [512, 512, 512]  EarlyStopping   \n",
       "12  dt2023_10Aug19_52_56               None    [512, 512, 512]  EarlyStopping   \n",
       "14  dt2023_10Aug21_26_14               None    [512, 512, 512]  EarlyStopping   \n",
       "19  dt2023_11Aug01_41_25               None    [512, 256, 512]  EarlyStopping   \n",
       "18  dt2023_11Aug00_59_23               None    [512, 256, 512]  EarlyStopping   \n",
       "9   dt2023_10Aug17_30_38               None    [512, 512, 512]  EarlyStopping   \n",
       "13  dt2023_10Aug20_36_08               None    [512, 512, 512]  EarlyStopping   \n",
       "2   dt2023_10Aug01_27_45               None    [512, 512, 512]  EarlyStopping   \n",
       "20  dt2023_11Aug02_29_04               None    [512, 256, 512]  EarlyStopping   \n",
       "1   dt2023_10Aug01_02_16               None    [512, 512, 512]           None   \n",
       "0   dt2023_10Aug00_51_32               None    [512, 512, 512]           None   \n",
       "6   dt2023_10Aug15_30_51                 l1    [512, 512, 512]           None   \n",
       "11  dt2023_10Aug19_06_33              l1_l2    [512, 512, 512]  EarlyStopping   \n",
       "7   dt2023_10Aug16_01_52                 l1    [512, 512, 512]  EarlyStopping   \n",
       "8   dt2023_10Aug16_56_37                 l1    [512, 512, 512]  EarlyStopping   \n",
       "10  dt2023_10Aug18_05_45                 l2    [512, 512, 512]  EarlyStopping   \n",
       "\n",
       "    dropout  mean_epoch  mean_f1_score_micro  std_f1_score_micro  \n",
       "5       0.0         NaN                 0.42                0.02  \n",
       "21      0.1         NaN                 0.41                0.00  \n",
       "15      0.1         NaN                 0.41                0.01  \n",
       "22      0.5         NaN                 0.41                0.01  \n",
       "17      0.5         NaN                 0.40                0.00  \n",
       "4       0.0         NaN                 0.40                0.01  \n",
       "16      0.3         NaN                 0.40                0.00  \n",
       "3       0.0         NaN                 0.39                0.01  \n",
       "24      0.1        43.2                 0.39                0.00  \n",
       "23      0.1        43.4                 0.39                0.00  \n",
       "12      0.1         NaN                 0.39                0.01  \n",
       "14      0.5         NaN                 0.38                0.00  \n",
       "19      0.3         NaN                 0.38                0.01  \n",
       "18      0.1         NaN                 0.38                0.00  \n",
       "9       0.0         NaN                 0.38                0.02  \n",
       "13      0.3         NaN                 0.38                0.00  \n",
       "2       0.0         NaN                 0.36                0.01  \n",
       "20      0.5         NaN                 0.36                0.00  \n",
       "1       0.0         NaN                 0.35                0.01  \n",
       "0       0.0         NaN                 0.33                0.01  \n",
       "6       0.0         NaN                 0.17                0.00  \n",
       "11      0.0         NaN                 0.17                0.00  \n",
       "7       0.1         NaN                 0.16                0.01  \n",
       "8       0.0         NaN                 0.16                0.01  \n",
       "10      0.0         NaN                 0.15                0.01  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Таблица отсортирована по убыванию mean_f1_score_micro\n",
    "eval_log_to_table(DIR_ROOT / 'experiments/eval.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "\n",
    "1. Наилучший результат показала модель №15 с [1024, 512, 1024] и `dropuot` 0.1, но  \n",
    "   превосходит другие незначительно, возможно погрешность.\n",
    "\n",
    "2. Применение регуляризации сильно снижает показатели ~ 0.15-0.17  \n",
    "   по mean_f1_score_micro\n",
    "\n",
    "3. Регулировка параметров EarlyStopping к значительным различиям в качестве  \n",
    "   моделей не привела (см. 15 запуск и 21, 17 запуск и 22 запуск.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
