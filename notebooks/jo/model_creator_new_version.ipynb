{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Использовать только процессор.\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "# Изменить уровень отображения логов\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "\n",
    "# Корень проекта.\n",
    "DIR_ROOT = Path.cwd().parent.parent\n",
    "sys.path.append(str(DIR_ROOT))\n",
    "import src.model_utils as mu\n",
    "from src.logger import eval_log_to_json, mean_epochs\n",
    "\n",
    "# Путь к удаленной директории с ресурсами: данные, модели и т.д.\n",
    "DIR_REMOTE: Path | None = Path('/home/admin/cafa/resources')\n",
    "\n",
    "if DIR_REMOTE is not None and DIR_REMOTE.exists():\n",
    "    DIR_RESOURCE = DIR_REMOTE\n",
    "else:\n",
    "    DIR_RESOURCE = DIR_ROOT\n",
    "\n",
    "# Путь к директории с подготовленными данными.\n",
    "DIR_PREPARED_DATA = DIR_RESOURCE / 'data/prepared'\n",
    "# Путь к файлу с оценкой моделей для различных экспериментов.\n",
    "PATH_TO_EVAL_FILE = DIR_ROOT / 'experiments/eval.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Утилиты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_shape_and_total_memory(df: pd.DataFrame, prefix: str = '') -> None:\n",
    "    '''\n",
    "    Вывод информации о форме и общем размере занятой памяти\n",
    "    объектаpd.DataFrame\n",
    "    '''\n",
    "    print(\n",
    "        prefix,\n",
    "        f'Shape: {df.shape}',\n",
    "        f'Total memory: {df.memory_usage().sum() / 1024**3:.1f} GB',\n",
    "        '---',\n",
    "        sep='\\n',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных (признаков, целей, IA-коэффициентов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "Shape: (142246, 1024)\n",
      "Total memory: 1.1 GB\n",
      "---\n",
      "y:\n",
      "Shape: (142246, 1500)\n",
      "Total memory: 0.8 GB\n",
      "---\n",
      "ia_arr:\n",
      "Shape: (1500,)\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_FEATURES = DIR_PREPARED_DATA / 'train_features_v2.csv'\n",
    "PATH_TO_LABELS = DIR_PREPARED_DATA / 'train_lbls_top1500_goterms_v2.csv'\n",
    "PATH_TO_IA_ARR = DIR_PREPARED_DATA / 'ai_arr_top1500_goterms_v2.npy'\n",
    "# Загрузка признаков.\n",
    "x = pd.read_csv(PATH_TO_FEATURES)\n",
    "# Загрузка целей.\n",
    "y = pd.read_csv(PATH_TO_LABELS)\n",
    "y = y.astype('int32')\n",
    "# Загрузка массива IA коэффициентов, соответсвующих GO-термам в `y.columns` \n",
    "ia_arr = np.load(PATH_TO_IA_ARR)\n",
    "\n",
    "print_shape_and_total_memory(x, 'x:')\n",
    "print_shape_and_total_memory(y, 'y:')\n",
    "print(f'ia_arr:\\nShape: {ia_arr.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка производительности модели\n",
    "Оценка производительности модели через KFold кросс-валидацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "23/23 [==============================] - 18s 719ms/step - loss: 0.2085 - binary_accuracy: 0.9328 - val_loss: 0.5811 - val_binary_accuracy: 0.9799\n",
      "Epoch 2/150\n",
      "23/23 [==============================] - 16s 692ms/step - loss: 0.0856 - binary_accuracy: 0.9795 - val_loss: 0.5606 - val_binary_accuracy: 0.9800\n",
      "Epoch 3/150\n",
      "23/23 [==============================] - 16s 679ms/step - loss: 0.0804 - binary_accuracy: 0.9798 - val_loss: 0.5459 - val_binary_accuracy: 0.9801\n",
      "Epoch 4/150\n",
      "23/23 [==============================] - 16s 686ms/step - loss: 0.0779 - binary_accuracy: 0.9800 - val_loss: 0.5279 - val_binary_accuracy: 0.9802\n",
      "Epoch 5/150\n",
      "23/23 [==============================] - 16s 685ms/step - loss: 0.0755 - binary_accuracy: 0.9801 - val_loss: 0.5041 - val_binary_accuracy: 0.9803\n",
      "Epoch 6/150\n",
      "23/23 [==============================] - 16s 678ms/step - loss: 0.0733 - binary_accuracy: 0.9802 - val_loss: 0.4852 - val_binary_accuracy: 0.9804\n",
      "Epoch 7/150\n",
      "23/23 [==============================] - 16s 681ms/step - loss: 0.0717 - binary_accuracy: 0.9802 - val_loss: 0.4576 - val_binary_accuracy: 0.9805\n",
      "Epoch 8/150\n",
      "23/23 [==============================] - 16s 681ms/step - loss: 0.0705 - binary_accuracy: 0.9803 - val_loss: 0.4327 - val_binary_accuracy: 0.9805\n",
      "Epoch 9/150\n",
      "23/23 [==============================] - 16s 686ms/step - loss: 0.0694 - binary_accuracy: 0.9804 - val_loss: 0.4098 - val_binary_accuracy: 0.9806\n",
      "Epoch 10/150\n",
      "23/23 [==============================] - 16s 682ms/step - loss: 0.0684 - binary_accuracy: 0.9805 - val_loss: 0.3844 - val_binary_accuracy: 0.9806\n",
      "Epoch 11/150\n",
      "23/23 [==============================] - 16s 680ms/step - loss: 0.0676 - binary_accuracy: 0.9805 - val_loss: 0.3584 - val_binary_accuracy: 0.9807\n",
      "Epoch 12/150\n",
      "23/23 [==============================] - 16s 680ms/step - loss: 0.0670 - binary_accuracy: 0.9806 - val_loss: 0.3410 - val_binary_accuracy: 0.9807\n",
      "Epoch 13/150\n",
      "23/23 [==============================] - 16s 684ms/step - loss: 0.0663 - binary_accuracy: 0.9806 - val_loss: 0.3111 - val_binary_accuracy: 0.9807\n",
      "Epoch 14/150\n",
      "23/23 [==============================] - 15s 677ms/step - loss: 0.0658 - binary_accuracy: 0.9807 - val_loss: 0.2863 - val_binary_accuracy: 0.9807\n",
      "Epoch 15/150\n",
      "23/23 [==============================] - 15s 674ms/step - loss: 0.0653 - binary_accuracy: 0.9807 - val_loss: 0.2688 - val_binary_accuracy: 0.9807\n",
      "Epoch 16/150\n",
      "23/23 [==============================] - 16s 680ms/step - loss: 0.0648 - binary_accuracy: 0.9808 - val_loss: 0.2406 - val_binary_accuracy: 0.9807\n",
      "Epoch 17/150\n",
      "23/23 [==============================] - 16s 692ms/step - loss: 0.0644 - binary_accuracy: 0.9808 - val_loss: 0.2207 - val_binary_accuracy: 0.9808\n",
      "Epoch 18/150\n",
      "23/23 [==============================] - 16s 685ms/step - loss: 0.0639 - binary_accuracy: 0.9808 - val_loss: 0.2015 - val_binary_accuracy: 0.9808\n",
      "Epoch 19/150\n",
      "23/23 [==============================] - 16s 678ms/step - loss: 0.0636 - binary_accuracy: 0.9809 - val_loss: 0.1830 - val_binary_accuracy: 0.9808\n",
      "Epoch 20/150\n",
      "23/23 [==============================] - 16s 684ms/step - loss: 0.0633 - binary_accuracy: 0.9809 - val_loss: 0.1632 - val_binary_accuracy: 0.9809\n",
      "Epoch 21/150\n",
      "23/23 [==============================] - 16s 679ms/step - loss: 0.0629 - binary_accuracy: 0.9809 - val_loss: 0.1509 - val_binary_accuracy: 0.9808\n",
      "Epoch 22/150\n",
      "23/23 [==============================] - 16s 685ms/step - loss: 0.0626 - binary_accuracy: 0.9810 - val_loss: 0.1371 - val_binary_accuracy: 0.9809\n",
      "Epoch 23/150\n",
      "23/23 [==============================] - 16s 680ms/step - loss: 0.0622 - binary_accuracy: 0.9810 - val_loss: 0.1250 - val_binary_accuracy: 0.9809\n",
      "Epoch 24/150\n",
      "23/23 [==============================] - 16s 692ms/step - loss: 0.0620 - binary_accuracy: 0.9810 - val_loss: 0.1101 - val_binary_accuracy: 0.9809\n",
      "Epoch 25/150\n",
      "23/23 [==============================] - 16s 684ms/step - loss: 0.0617 - binary_accuracy: 0.9811 - val_loss: 0.1017 - val_binary_accuracy: 0.9809\n",
      "Epoch 26/150\n",
      "23/23 [==============================] - 15s 676ms/step - loss: 0.0614 - binary_accuracy: 0.9811 - val_loss: 0.0973 - val_binary_accuracy: 0.9809\n",
      "Epoch 27/150\n",
      "23/23 [==============================] - 16s 677ms/step - loss: 0.0612 - binary_accuracy: 0.9811 - val_loss: 0.0898 - val_binary_accuracy: 0.9809\n",
      "Epoch 28/150\n",
      "23/23 [==============================] - 16s 678ms/step - loss: 0.0609 - binary_accuracy: 0.9812 - val_loss: 0.0831 - val_binary_accuracy: 0.9810\n",
      "Epoch 29/150\n",
      "23/23 [==============================] - 15s 675ms/step - loss: 0.0606 - binary_accuracy: 0.9812 - val_loss: 0.0805 - val_binary_accuracy: 0.9809\n",
      "Epoch 30/150\n",
      "23/23 [==============================] - 16s 681ms/step - loss: 0.0604 - binary_accuracy: 0.9812 - val_loss: 0.0764 - val_binary_accuracy: 0.9810\n",
      "Epoch 31/150\n",
      "23/23 [==============================] - 16s 691ms/step - loss: 0.0601 - binary_accuracy: 0.9812 - val_loss: 0.0755 - val_binary_accuracy: 0.9809\n",
      "Epoch 32/150\n",
      "23/23 [==============================] - 16s 684ms/step - loss: 0.0599 - binary_accuracy: 0.9813 - val_loss: 0.0723 - val_binary_accuracy: 0.9810\n",
      "Epoch 33/150\n",
      "23/23 [==============================] - 16s 684ms/step - loss: 0.0597 - binary_accuracy: 0.9813 - val_loss: 0.0703 - val_binary_accuracy: 0.9810\n",
      "Epoch 34/150\n",
      "23/23 [==============================] - 16s 678ms/step - loss: 0.0594 - binary_accuracy: 0.9813 - val_loss: 0.0701 - val_binary_accuracy: 0.9809\n",
      "Epoch 35/150\n",
      "23/23 [==============================] - 16s 681ms/step - loss: 0.0593 - binary_accuracy: 0.9814 - val_loss: 0.0684 - val_binary_accuracy: 0.9810\n",
      "Epoch 36/150\n",
      "23/23 [==============================] - 16s 682ms/step - loss: 0.0590 - binary_accuracy: 0.9814 - val_loss: 0.0666 - val_binary_accuracy: 0.9811\n",
      "Epoch 37/150\n",
      "23/23 [==============================] - 16s 683ms/step - loss: 0.0589 - binary_accuracy: 0.9814 - val_loss: 0.0661 - val_binary_accuracy: 0.9811\n",
      "Epoch 38/150\n",
      "23/23 [==============================] - 15s 675ms/step - loss: 0.0586 - binary_accuracy: 0.9815 - val_loss: 0.0654 - val_binary_accuracy: 0.9811\n",
      "Epoch 39/150\n",
      "23/23 [==============================] - 16s 682ms/step - loss: 0.0584 - binary_accuracy: 0.9815 - val_loss: 0.0659 - val_binary_accuracy: 0.9811\n",
      "Epoch 40/150\n",
      "23/23 [==============================] - 16s 678ms/step - loss: 0.0582 - binary_accuracy: 0.9815 - val_loss: 0.0645 - val_binary_accuracy: 0.9811\n",
      "Epoch 41/150\n",
      "23/23 [==============================] - 16s 682ms/step - loss: 0.0580 - binary_accuracy: 0.9816 - val_loss: 0.0650 - val_binary_accuracy: 0.9811\n",
      "Epoch 42/150\n",
      "23/23 [==============================] - 16s 679ms/step - loss: 0.0578 - binary_accuracy: 0.9816 - val_loss: 0.0640 - val_binary_accuracy: 0.9812\n",
      "890/890 [==============================] - 4s 5ms/step\n",
      "Epoch 1/150\n",
      "23/23 [==============================] - 18s 707ms/step - loss: 0.2113 - binary_accuracy: 0.9320 - val_loss: 0.5773 - val_binary_accuracy: 0.9800\n",
      "Epoch 2/150\n",
      "23/23 [==============================] - 16s 688ms/step - loss: 0.0856 - binary_accuracy: 0.9795 - val_loss: 0.5557 - val_binary_accuracy: 0.9800\n",
      "Epoch 3/150\n",
      "23/23 [==============================] - 16s 677ms/step - loss: 0.0804 - binary_accuracy: 0.9798 - val_loss: 0.5454 - val_binary_accuracy: 0.9801\n",
      "Epoch 4/150\n",
      "23/23 [==============================] - 16s 683ms/step - loss: 0.0778 - binary_accuracy: 0.9799 - val_loss: 0.5263 - val_binary_accuracy: 0.9802\n",
      "Epoch 5/150\n",
      "23/23 [==============================] - 16s 686ms/step - loss: 0.0754 - binary_accuracy: 0.9801 - val_loss: 0.5055 - val_binary_accuracy: 0.9804\n",
      "Epoch 6/150\n",
      "23/23 [==============================] - 16s 691ms/step - loss: 0.0734 - binary_accuracy: 0.9801 - val_loss: 0.4824 - val_binary_accuracy: 0.9805\n",
      "Epoch 7/150\n",
      "23/23 [==============================] - 16s 682ms/step - loss: 0.0718 - binary_accuracy: 0.9802 - val_loss: 0.4588 - val_binary_accuracy: 0.9806\n",
      "Epoch 8/150\n",
      "23/23 [==============================] - 16s 687ms/step - loss: 0.0705 - binary_accuracy: 0.9803 - val_loss: 0.4360 - val_binary_accuracy: 0.9806\n",
      "Epoch 9/150\n",
      "23/23 [==============================] - 16s 684ms/step - loss: 0.0695 - binary_accuracy: 0.9804 - val_loss: 0.4105 - val_binary_accuracy: 0.9807\n",
      "Epoch 10/150\n",
      "23/23 [==============================] - 16s 689ms/step - loss: 0.0686 - binary_accuracy: 0.9804 - val_loss: 0.3864 - val_binary_accuracy: 0.9807\n",
      "Epoch 11/150\n",
      "23/23 [==============================] - 16s 681ms/step - loss: 0.0678 - binary_accuracy: 0.9805 - val_loss: 0.3629 - val_binary_accuracy: 0.9807\n",
      "Epoch 12/150\n",
      "23/23 [==============================] - 16s 685ms/step - loss: 0.0671 - binary_accuracy: 0.9805 - val_loss: 0.3331 - val_binary_accuracy: 0.9808\n",
      "Epoch 13/150\n",
      "23/23 [==============================] - 15s 675ms/step - loss: 0.0664 - binary_accuracy: 0.9806 - val_loss: 0.3129 - val_binary_accuracy: 0.9808\n",
      "Epoch 14/150\n",
      "23/23 [==============================] - 16s 681ms/step - loss: 0.0658 - binary_accuracy: 0.9806 - val_loss: 0.2917 - val_binary_accuracy: 0.9808\n",
      "Epoch 15/150\n",
      "23/23 [==============================] - 16s 682ms/step - loss: 0.0653 - binary_accuracy: 0.9807 - val_loss: 0.2709 - val_binary_accuracy: 0.9809\n",
      "Epoch 16/150\n",
      "23/23 [==============================] - 16s 681ms/step - loss: 0.0649 - binary_accuracy: 0.9807 - val_loss: 0.2503 - val_binary_accuracy: 0.9809\n",
      "Epoch 17/150\n",
      "23/23 [==============================] - 16s 707ms/step - loss: 0.0644 - binary_accuracy: 0.9808 - val_loss: 0.2271 - val_binary_accuracy: 0.9809\n",
      "Epoch 18/150\n",
      "23/23 [==============================] - 15s 676ms/step - loss: 0.0640 - binary_accuracy: 0.9808 - val_loss: 0.2074 - val_binary_accuracy: 0.9808\n",
      "Epoch 19/150\n",
      "23/23 [==============================] - 16s 681ms/step - loss: 0.0637 - binary_accuracy: 0.9808 - val_loss: 0.1822 - val_binary_accuracy: 0.9810\n",
      "Epoch 20/150\n",
      "23/23 [==============================] - 16s 683ms/step - loss: 0.0634 - binary_accuracy: 0.9809 - val_loss: 0.1668 - val_binary_accuracy: 0.9810\n",
      "Epoch 21/150\n",
      "23/23 [==============================] - 16s 685ms/step - loss: 0.0630 - binary_accuracy: 0.9809 - val_loss: 0.1478 - val_binary_accuracy: 0.9811\n",
      "Epoch 22/150\n",
      "23/23 [==============================] - 15s 676ms/step - loss: 0.0627 - binary_accuracy: 0.9810 - val_loss: 0.1329 - val_binary_accuracy: 0.9810\n",
      "Epoch 23/150\n",
      "23/23 [==============================] - 16s 686ms/step - loss: 0.0624 - binary_accuracy: 0.9810 - val_loss: 0.1247 - val_binary_accuracy: 0.9810\n",
      "Epoch 24/150\n",
      "23/23 [==============================] - 16s 690ms/step - loss: 0.0621 - binary_accuracy: 0.9810 - val_loss: 0.1139 - val_binary_accuracy: 0.9810\n",
      "Epoch 25/150\n",
      "23/23 [==============================] - 16s 683ms/step - loss: 0.0618 - binary_accuracy: 0.9811 - val_loss: 0.1045 - val_binary_accuracy: 0.9810\n",
      "Epoch 26/150\n",
      "23/23 [==============================] - 16s 682ms/step - loss: 0.0615 - binary_accuracy: 0.9811 - val_loss: 0.0963 - val_binary_accuracy: 0.9810\n",
      "Epoch 27/150\n",
      "23/23 [==============================] - 16s 690ms/step - loss: 0.0613 - binary_accuracy: 0.9811 - val_loss: 0.0888 - val_binary_accuracy: 0.9810\n",
      "Epoch 28/150\n",
      "23/23 [==============================] - 16s 677ms/step - loss: 0.0610 - binary_accuracy: 0.9811 - val_loss: 0.0848 - val_binary_accuracy: 0.9811\n",
      "Epoch 29/150\n",
      "23/23 [==============================] - 16s 678ms/step - loss: 0.0607 - binary_accuracy: 0.9812 - val_loss: 0.0811 - val_binary_accuracy: 0.9811\n",
      "Epoch 30/150\n",
      "23/23 [==============================] - 16s 689ms/step - loss: 0.0604 - binary_accuracy: 0.9812 - val_loss: 0.0775 - val_binary_accuracy: 0.9811\n",
      "Epoch 31/150\n",
      "23/23 [==============================] - 16s 695ms/step - loss: 0.0603 - binary_accuracy: 0.9812 - val_loss: 0.0731 - val_binary_accuracy: 0.9811\n",
      "Epoch 32/150\n",
      "23/23 [==============================] - 16s 693ms/step - loss: 0.0600 - binary_accuracy: 0.9813 - val_loss: 0.0714 - val_binary_accuracy: 0.9811\n",
      "Epoch 33/150\n",
      "23/23 [==============================] - 16s 676ms/step - loss: 0.0598 - binary_accuracy: 0.9813 - val_loss: 0.0694 - val_binary_accuracy: 0.9812\n",
      "Epoch 34/150\n",
      "23/23 [==============================] - 16s 717ms/step - loss: 0.0596 - binary_accuracy: 0.9813 - val_loss: 0.0690 - val_binary_accuracy: 0.9811\n",
      "Epoch 35/150\n",
      "23/23 [==============================] - 16s 694ms/step - loss: 0.0593 - binary_accuracy: 0.9814 - val_loss: 0.0681 - val_binary_accuracy: 0.9812\n",
      "Epoch 36/150\n",
      "23/23 [==============================] - 16s 682ms/step - loss: 0.0591 - binary_accuracy: 0.9814 - val_loss: 0.0669 - val_binary_accuracy: 0.9813\n",
      "Epoch 37/150\n",
      "23/23 [==============================] - 16s 678ms/step - loss: 0.0589 - binary_accuracy: 0.9814 - val_loss: 0.0667 - val_binary_accuracy: 0.9812\n",
      "Epoch 38/150\n",
      "23/23 [==============================] - 16s 680ms/step - loss: 0.0587 - binary_accuracy: 0.9815 - val_loss: 0.0655 - val_binary_accuracy: 0.9813\n",
      "Epoch 39/150\n",
      "23/23 [==============================] - 16s 680ms/step - loss: 0.0585 - binary_accuracy: 0.9815 - val_loss: 0.0651 - val_binary_accuracy: 0.9812\n",
      "Epoch 40/150\n",
      "23/23 [==============================] - 16s 678ms/step - loss: 0.0583 - binary_accuracy: 0.9815 - val_loss: 0.0647 - val_binary_accuracy: 0.9813\n",
      "Epoch 41/150\n",
      "23/23 [==============================] - 16s 678ms/step - loss: 0.0581 - binary_accuracy: 0.9815 - val_loss: 0.0640 - val_binary_accuracy: 0.9814\n",
      "890/890 [==============================] - 4s 5ms/step\n",
      "Epoch 1/150\n",
      "23/23 [==============================] - 18s 697ms/step - loss: 0.2081 - binary_accuracy: 0.9334 - val_loss: 0.5730 - val_binary_accuracy: 0.9802\n",
      "Epoch 2/150\n",
      "23/23 [==============================] - 16s 678ms/step - loss: 0.0858 - binary_accuracy: 0.9795 - val_loss: 0.5595 - val_binary_accuracy: 0.9803\n",
      "Epoch 3/150\n",
      "23/23 [==============================] - 16s 685ms/step - loss: 0.0804 - binary_accuracy: 0.9797 - val_loss: 0.5443 - val_binary_accuracy: 0.9804\n",
      "Epoch 4/150\n",
      "23/23 [==============================] - 16s 683ms/step - loss: 0.0778 - binary_accuracy: 0.9799 - val_loss: 0.5251 - val_binary_accuracy: 0.9805\n",
      "Epoch 5/150\n",
      "23/23 [==============================] - 16s 684ms/step - loss: 0.0754 - binary_accuracy: 0.9800 - val_loss: 0.5029 - val_binary_accuracy: 0.9806\n",
      "Epoch 6/150\n",
      "23/23 [==============================] - 15s 676ms/step - loss: 0.0734 - binary_accuracy: 0.9801 - val_loss: 0.4805 - val_binary_accuracy: 0.9807\n",
      "Epoch 7/150\n",
      "23/23 [==============================] - 16s 683ms/step - loss: 0.0718 - binary_accuracy: 0.9802 - val_loss: 0.4570 - val_binary_accuracy: 0.9808\n",
      "Epoch 8/150\n",
      "23/23 [==============================] - 16s 691ms/step - loss: 0.0706 - binary_accuracy: 0.9803 - val_loss: 0.4322 - val_binary_accuracy: 0.9808\n",
      "Epoch 9/150\n",
      "23/23 [==============================] - 16s 687ms/step - loss: 0.0695 - binary_accuracy: 0.9803 - val_loss: 0.4100 - val_binary_accuracy: 0.9809\n",
      "Epoch 10/150\n",
      "23/23 [==============================] - 15s 674ms/step - loss: 0.0687 - binary_accuracy: 0.9804 - val_loss: 0.3822 - val_binary_accuracy: 0.9809\n",
      "Epoch 11/150\n",
      "23/23 [==============================] - 16s 682ms/step - loss: 0.0679 - binary_accuracy: 0.9805 - val_loss: 0.3621 - val_binary_accuracy: 0.9809\n",
      "Epoch 12/150\n",
      "23/23 [==============================] - 16s 682ms/step - loss: 0.0672 - binary_accuracy: 0.9805 - val_loss: 0.3415 - val_binary_accuracy: 0.9809\n",
      "Epoch 13/150\n",
      "23/23 [==============================] - 16s 680ms/step - loss: 0.0665 - binary_accuracy: 0.9806 - val_loss: 0.3142 - val_binary_accuracy: 0.9810\n",
      "Epoch 14/150\n",
      "23/23 [==============================] - 16s 681ms/step - loss: 0.0660 - binary_accuracy: 0.9806 - val_loss: 0.2895 - val_binary_accuracy: 0.9810\n",
      "Epoch 15/150\n",
      "23/23 [==============================] - 16s 687ms/step - loss: 0.0655 - binary_accuracy: 0.9806 - val_loss: 0.2678 - val_binary_accuracy: 0.9811\n",
      "Epoch 16/150\n",
      "23/23 [==============================] - 16s 681ms/step - loss: 0.0651 - binary_accuracy: 0.9807 - val_loss: 0.2450 - val_binary_accuracy: 0.9811\n",
      "Epoch 17/150\n",
      "23/23 [==============================] - 16s 683ms/step - loss: 0.0646 - binary_accuracy: 0.9807 - val_loss: 0.2225 - val_binary_accuracy: 0.9811\n",
      "Epoch 18/150\n",
      "23/23 [==============================] - 16s 683ms/step - loss: 0.0642 - binary_accuracy: 0.9808 - val_loss: 0.2010 - val_binary_accuracy: 0.9811\n",
      "Epoch 19/150\n",
      "23/23 [==============================] - 15s 668ms/step - loss: 0.0639 - binary_accuracy: 0.9808 - val_loss: 0.1817 - val_binary_accuracy: 0.9812\n",
      "Epoch 20/150\n",
      "23/23 [==============================] - 16s 682ms/step - loss: 0.0636 - binary_accuracy: 0.9808 - val_loss: 0.1640 - val_binary_accuracy: 0.9811\n",
      "Epoch 21/150\n",
      "23/23 [==============================] - 16s 687ms/step - loss: 0.0632 - binary_accuracy: 0.9809 - val_loss: 0.1519 - val_binary_accuracy: 0.9811\n",
      "Epoch 22/150\n",
      "23/23 [==============================] - 16s 681ms/step - loss: 0.0629 - binary_accuracy: 0.9809 - val_loss: 0.1377 - val_binary_accuracy: 0.9812\n",
      "Epoch 23/150\n",
      "23/23 [==============================] - 16s 684ms/step - loss: 0.0625 - binary_accuracy: 0.9810 - val_loss: 0.1200 - val_binary_accuracy: 0.9812\n",
      "Epoch 24/150\n",
      "23/23 [==============================] - 15s 671ms/step - loss: 0.0622 - binary_accuracy: 0.9810 - val_loss: 0.1105 - val_binary_accuracy: 0.9813\n",
      "Epoch 25/150\n",
      "23/23 [==============================] - 16s 682ms/step - loss: 0.0620 - binary_accuracy: 0.9810 - val_loss: 0.1007 - val_binary_accuracy: 0.9813\n",
      "Epoch 26/150\n",
      "23/23 [==============================] - 16s 682ms/step - loss: 0.0617 - binary_accuracy: 0.9810 - val_loss: 0.0946 - val_binary_accuracy: 0.9812\n",
      "Epoch 27/150\n",
      "23/23 [==============================] - 16s 686ms/step - loss: 0.0614 - binary_accuracy: 0.9811 - val_loss: 0.0887 - val_binary_accuracy: 0.9813\n",
      "Epoch 28/150\n",
      "23/23 [==============================] - 15s 671ms/step - loss: 0.0612 - binary_accuracy: 0.9811 - val_loss: 0.0826 - val_binary_accuracy: 0.9813\n",
      "Epoch 29/150\n",
      "23/23 [==============================] - 16s 704ms/step - loss: 0.0609 - binary_accuracy: 0.9811 - val_loss: 0.0781 - val_binary_accuracy: 0.9814\n",
      "Epoch 30/150\n",
      "23/23 [==============================] - 16s 680ms/step - loss: 0.0607 - binary_accuracy: 0.9812 - val_loss: 0.0760 - val_binary_accuracy: 0.9813\n",
      "Epoch 31/150\n",
      "23/23 [==============================] - 16s 682ms/step - loss: 0.0604 - binary_accuracy: 0.9812 - val_loss: 0.0735 - val_binary_accuracy: 0.9813\n",
      "Epoch 32/150\n",
      "23/23 [==============================] - 16s 681ms/step - loss: 0.0602 - binary_accuracy: 0.9812 - val_loss: 0.0703 - val_binary_accuracy: 0.9813\n",
      "Epoch 33/150\n",
      "23/23 [==============================] - 16s 680ms/step - loss: 0.0600 - binary_accuracy: 0.9813 - val_loss: 0.0694 - val_binary_accuracy: 0.9814\n",
      "Epoch 34/150\n",
      "23/23 [==============================] - 16s 683ms/step - loss: 0.0598 - binary_accuracy: 0.9813 - val_loss: 0.0677 - val_binary_accuracy: 0.9814\n",
      "Epoch 35/150\n",
      "23/23 [==============================] - 16s 684ms/step - loss: 0.0596 - binary_accuracy: 0.9813 - val_loss: 0.0666 - val_binary_accuracy: 0.9814\n",
      "Epoch 36/150\n",
      "23/23 [==============================] - 16s 679ms/step - loss: 0.0593 - binary_accuracy: 0.9814 - val_loss: 0.0664 - val_binary_accuracy: 0.9814\n",
      "Epoch 37/150\n",
      "23/23 [==============================] - 15s 675ms/step - loss: 0.0591 - binary_accuracy: 0.9814 - val_loss: 0.0650 - val_binary_accuracy: 0.9814\n",
      "Epoch 38/150\n",
      "23/23 [==============================] - 15s 677ms/step - loss: 0.0589 - binary_accuracy: 0.9814 - val_loss: 0.0649 - val_binary_accuracy: 0.9815\n",
      "Epoch 39/150\n",
      "23/23 [==============================] - 16s 683ms/step - loss: 0.0587 - binary_accuracy: 0.9814 - val_loss: 0.0637 - val_binary_accuracy: 0.9815\n",
      "Epoch 40/150\n",
      "23/23 [==============================] - 16s 684ms/step - loss: 0.0584 - binary_accuracy: 0.9815 - val_loss: 0.0635 - val_binary_accuracy: 0.9814\n",
      "Epoch 41/150\n",
      "23/23 [==============================] - 16s 677ms/step - loss: 0.0583 - binary_accuracy: 0.9815 - val_loss: 0.0626 - val_binary_accuracy: 0.9816\n",
      "Epoch 42/150\n",
      "23/23 [==============================] - 16s 685ms/step - loss: 0.0581 - binary_accuracy: 0.9815 - val_loss: 0.0629 - val_binary_accuracy: 0.9816\n",
      "Epoch 43/150\n",
      "23/23 [==============================] - 16s 677ms/step - loss: 0.0580 - binary_accuracy: 0.9816 - val_loss: 0.0623 - val_binary_accuracy: 0.9816\n",
      "Epoch 44/150\n",
      "23/23 [==============================] - 16s 684ms/step - loss: 0.0578 - binary_accuracy: 0.9816 - val_loss: 0.0628 - val_binary_accuracy: 0.9816\n",
      "890/890 [==============================] - 4s 5ms/step\n",
      "Epoch 1/150\n",
      "23/23 [==============================] - 18s 693ms/step - loss: 0.2057 - binary_accuracy: 0.9336 - val_loss: 0.5768 - val_binary_accuracy: 0.9800\n",
      "Epoch 2/150\n",
      "23/23 [==============================] - 16s 680ms/step - loss: 0.0857 - binary_accuracy: 0.9795 - val_loss: 0.5630 - val_binary_accuracy: 0.9801\n",
      "Epoch 3/150\n",
      "23/23 [==============================] - 16s 681ms/step - loss: 0.0803 - binary_accuracy: 0.9797 - val_loss: 0.5442 - val_binary_accuracy: 0.9803\n",
      "Epoch 4/150\n",
      "23/23 [==============================] - 15s 674ms/step - loss: 0.0778 - binary_accuracy: 0.9800 - val_loss: 0.5230 - val_binary_accuracy: 0.9804\n",
      "Epoch 5/150\n",
      "23/23 [==============================] - 16s 684ms/step - loss: 0.0752 - binary_accuracy: 0.9801 - val_loss: 0.5034 - val_binary_accuracy: 0.9805\n",
      "Epoch 6/150\n",
      "23/23 [==============================] - 15s 671ms/step - loss: 0.0732 - binary_accuracy: 0.9802 - val_loss: 0.4810 - val_binary_accuracy: 0.9805\n",
      "Epoch 7/150\n",
      "23/23 [==============================] - 16s 682ms/step - loss: 0.0718 - binary_accuracy: 0.9803 - val_loss: 0.4563 - val_binary_accuracy: 0.9806\n",
      "Epoch 8/150\n",
      "23/23 [==============================] - 16s 681ms/step - loss: 0.0706 - binary_accuracy: 0.9803 - val_loss: 0.4335 - val_binary_accuracy: 0.9807\n",
      "Epoch 9/150\n",
      "23/23 [==============================] - 16s 691ms/step - loss: 0.0695 - binary_accuracy: 0.9804 - val_loss: 0.4088 - val_binary_accuracy: 0.9807\n",
      "Epoch 10/150\n",
      "23/23 [==============================] - 16s 693ms/step - loss: 0.0687 - binary_accuracy: 0.9804 - val_loss: 0.3851 - val_binary_accuracy: 0.9807\n",
      "Epoch 11/150\n",
      "23/23 [==============================] - 16s 687ms/step - loss: 0.0679 - binary_accuracy: 0.9805 - val_loss: 0.3637 - val_binary_accuracy: 0.9808\n",
      "Epoch 12/150\n",
      "23/23 [==============================] - 16s 684ms/step - loss: 0.0671 - binary_accuracy: 0.9806 - val_loss: 0.3359 - val_binary_accuracy: 0.9808\n",
      "Epoch 13/150\n",
      "23/23 [==============================] - 16s 686ms/step - loss: 0.0665 - binary_accuracy: 0.9806 - val_loss: 0.3152 - val_binary_accuracy: 0.9808\n",
      "Epoch 14/150\n",
      "23/23 [==============================] - 16s 679ms/step - loss: 0.0659 - binary_accuracy: 0.9807 - val_loss: 0.2913 - val_binary_accuracy: 0.9809\n",
      "Epoch 15/150\n",
      "23/23 [==============================] - 16s 685ms/step - loss: 0.0655 - binary_accuracy: 0.9807 - val_loss: 0.2671 - val_binary_accuracy: 0.9808\n",
      "Epoch 16/150\n",
      "23/23 [==============================] - 16s 680ms/step - loss: 0.0650 - binary_accuracy: 0.9807 - val_loss: 0.2450 - val_binary_accuracy: 0.9809\n",
      "Epoch 17/150\n",
      "23/23 [==============================] - 16s 680ms/step - loss: 0.0645 - binary_accuracy: 0.9808 - val_loss: 0.2225 - val_binary_accuracy: 0.9810\n",
      "Epoch 18/150\n",
      "23/23 [==============================] - 16s 688ms/step - loss: 0.0641 - binary_accuracy: 0.9808 - val_loss: 0.2022 - val_binary_accuracy: 0.9810\n",
      "Epoch 19/150\n",
      "23/23 [==============================] - 16s 682ms/step - loss: 0.0638 - binary_accuracy: 0.9808 - val_loss: 0.1823 - val_binary_accuracy: 0.9810\n",
      "Epoch 20/150\n",
      "23/23 [==============================] - 16s 687ms/step - loss: 0.0634 - binary_accuracy: 0.9809 - val_loss: 0.1629 - val_binary_accuracy: 0.9810\n",
      "Epoch 21/150\n",
      "23/23 [==============================] - 16s 681ms/step - loss: 0.0630 - binary_accuracy: 0.9809 - val_loss: 0.1512 - val_binary_accuracy: 0.9810\n",
      "Epoch 22/150\n",
      "23/23 [==============================] - 16s 684ms/step - loss: 0.0627 - binary_accuracy: 0.9810 - val_loss: 0.1356 - val_binary_accuracy: 0.9810\n",
      "Epoch 23/150\n",
      "23/23 [==============================] - 16s 685ms/step - loss: 0.0624 - binary_accuracy: 0.9810 - val_loss: 0.1235 - val_binary_accuracy: 0.9811\n",
      "Epoch 24/150\n",
      "23/23 [==============================] - 16s 690ms/step - loss: 0.0621 - binary_accuracy: 0.9810 - val_loss: 0.1112 - val_binary_accuracy: 0.9811\n",
      "Epoch 25/150\n",
      "23/23 [==============================] - 16s 682ms/step - loss: 0.0618 - binary_accuracy: 0.9810 - val_loss: 0.0997 - val_binary_accuracy: 0.9811\n",
      "Epoch 26/150\n",
      "23/23 [==============================] - 16s 680ms/step - loss: 0.0615 - binary_accuracy: 0.9811 - val_loss: 0.0949 - val_binary_accuracy: 0.9811\n",
      "Epoch 27/150\n",
      "23/23 [==============================] - 16s 677ms/step - loss: 0.0613 - binary_accuracy: 0.9811 - val_loss: 0.0879 - val_binary_accuracy: 0.9811\n",
      "Epoch 28/150\n",
      "23/23 [==============================] - 16s 687ms/step - loss: 0.0610 - binary_accuracy: 0.9811 - val_loss: 0.0826 - val_binary_accuracy: 0.9812\n",
      "Epoch 29/150\n",
      "23/23 [==============================] - 16s 682ms/step - loss: 0.0607 - binary_accuracy: 0.9812 - val_loss: 0.0785 - val_binary_accuracy: 0.9812\n",
      "Epoch 30/150\n",
      "23/23 [==============================] - 16s 682ms/step - loss: 0.0604 - binary_accuracy: 0.9812 - val_loss: 0.0762 - val_binary_accuracy: 0.9811\n",
      "Epoch 31/150\n",
      "23/23 [==============================] - 16s 686ms/step - loss: 0.0602 - binary_accuracy: 0.9812 - val_loss: 0.0738 - val_binary_accuracy: 0.9811\n",
      "Epoch 32/150\n",
      "23/23 [==============================] - 16s 687ms/step - loss: 0.0600 - binary_accuracy: 0.9813 - val_loss: 0.0724 - val_binary_accuracy: 0.9812\n",
      "Epoch 33/150\n",
      "23/23 [==============================] - 16s 683ms/step - loss: 0.0598 - binary_accuracy: 0.9813 - val_loss: 0.0701 - val_binary_accuracy: 0.9813\n",
      "Epoch 34/150\n",
      "23/23 [==============================] - 16s 687ms/step - loss: 0.0596 - binary_accuracy: 0.9813 - val_loss: 0.0689 - val_binary_accuracy: 0.9812\n",
      "Epoch 35/150\n",
      "23/23 [==============================] - 16s 680ms/step - loss: 0.0593 - binary_accuracy: 0.9814 - val_loss: 0.0663 - val_binary_accuracy: 0.9813\n",
      "Epoch 36/150\n",
      "23/23 [==============================] - 16s 683ms/step - loss: 0.0591 - binary_accuracy: 0.9814 - val_loss: 0.0652 - val_binary_accuracy: 0.9813\n",
      "Epoch 37/150\n",
      "23/23 [==============================] - 15s 673ms/step - loss: 0.0589 - binary_accuracy: 0.9814 - val_loss: 0.0662 - val_binary_accuracy: 0.9812\n",
      "Epoch 38/150\n",
      "23/23 [==============================] - 16s 680ms/step - loss: 0.0586 - binary_accuracy: 0.9814 - val_loss: 0.0653 - val_binary_accuracy: 0.9812\n",
      "Epoch 39/150\n",
      "23/23 [==============================] - 16s 677ms/step - loss: 0.0585 - binary_accuracy: 0.9815 - val_loss: 0.0647 - val_binary_accuracy: 0.9813\n",
      "Epoch 40/150\n",
      "23/23 [==============================] - 16s 686ms/step - loss: 0.0583 - binary_accuracy: 0.9815 - val_loss: 0.0644 - val_binary_accuracy: 0.9813\n",
      "Epoch 41/150\n",
      "23/23 [==============================] - 16s 692ms/step - loss: 0.0582 - binary_accuracy: 0.9815 - val_loss: 0.0643 - val_binary_accuracy: 0.9813\n",
      "Epoch 42/150\n",
      "23/23 [==============================] - 16s 689ms/step - loss: 0.0579 - binary_accuracy: 0.9816 - val_loss: 0.0632 - val_binary_accuracy: 0.9814\n",
      "Epoch 43/150\n",
      "23/23 [==============================] - 16s 695ms/step - loss: 0.0577 - binary_accuracy: 0.9816 - val_loss: 0.0639 - val_binary_accuracy: 0.9814\n",
      "Epoch 44/150\n",
      "23/23 [==============================] - 16s 704ms/step - loss: 0.0575 - binary_accuracy: 0.9816 - val_loss: 0.0628 - val_binary_accuracy: 0.9814\n",
      "Epoch 45/150\n",
      "23/23 [==============================] - 16s 697ms/step - loss: 0.0573 - binary_accuracy: 0.9817 - val_loss: 0.0621 - val_binary_accuracy: 0.9815\n",
      "Epoch 46/150\n",
      "23/23 [==============================] - 16s 683ms/step - loss: 0.0572 - binary_accuracy: 0.9817 - val_loss: 0.0621 - val_binary_accuracy: 0.9815\n",
      "890/890 [==============================] - 5s 5ms/step\n",
      "Epoch 1/150\n",
      "23/23 [==============================] - 18s 693ms/step - loss: 0.2043 - binary_accuracy: 0.9347 - val_loss: 0.5706 - val_binary_accuracy: 0.9800\n",
      "Epoch 2/150\n",
      "23/23 [==============================] - 16s 682ms/step - loss: 0.0857 - binary_accuracy: 0.9795 - val_loss: 0.5624 - val_binary_accuracy: 0.9800\n",
      "Epoch 3/150\n",
      "23/23 [==============================] - 16s 683ms/step - loss: 0.0803 - binary_accuracy: 0.9797 - val_loss: 0.5439 - val_binary_accuracy: 0.9802\n",
      "Epoch 4/150\n",
      "23/23 [==============================] - 16s 689ms/step - loss: 0.0777 - binary_accuracy: 0.9799 - val_loss: 0.5262 - val_binary_accuracy: 0.9803\n",
      "Epoch 5/150\n",
      "23/23 [==============================] - 16s 695ms/step - loss: 0.0752 - binary_accuracy: 0.9801 - val_loss: 0.5035 - val_binary_accuracy: 0.9804\n",
      "Epoch 6/150\n",
      "23/23 [==============================] - 16s 680ms/step - loss: 0.0731 - binary_accuracy: 0.9802 - val_loss: 0.4830 - val_binary_accuracy: 0.9805\n",
      "Epoch 7/150\n",
      "23/23 [==============================] - 16s 687ms/step - loss: 0.0715 - binary_accuracy: 0.9803 - val_loss: 0.4586 - val_binary_accuracy: 0.9806\n",
      "Epoch 8/150\n",
      "23/23 [==============================] - 16s 682ms/step - loss: 0.0703 - binary_accuracy: 0.9803 - val_loss: 0.4341 - val_binary_accuracy: 0.9806\n",
      "Epoch 9/150\n",
      "23/23 [==============================] - 16s 680ms/step - loss: 0.0692 - binary_accuracy: 0.9804 - val_loss: 0.4114 - val_binary_accuracy: 0.9806\n",
      "Epoch 10/150\n",
      "23/23 [==============================] - 16s 681ms/step - loss: 0.0684 - binary_accuracy: 0.9805 - val_loss: 0.3860 - val_binary_accuracy: 0.9807\n",
      "Epoch 11/150\n",
      "23/23 [==============================] - 16s 689ms/step - loss: 0.0676 - binary_accuracy: 0.9805 - val_loss: 0.3644 - val_binary_accuracy: 0.9807\n",
      "Epoch 12/150\n",
      "23/23 [==============================] - 16s 679ms/step - loss: 0.0669 - binary_accuracy: 0.9806 - val_loss: 0.3318 - val_binary_accuracy: 0.9808\n",
      "Epoch 13/150\n",
      "23/23 [==============================] - 16s 678ms/step - loss: 0.0663 - binary_accuracy: 0.9806 - val_loss: 0.3134 - val_binary_accuracy: 0.9808\n",
      "Epoch 14/150\n",
      "23/23 [==============================] - 16s 688ms/step - loss: 0.0657 - binary_accuracy: 0.9807 - val_loss: 0.2943 - val_binary_accuracy: 0.9809\n",
      "Epoch 15/150\n",
      "23/23 [==============================] - 16s 687ms/step - loss: 0.0652 - binary_accuracy: 0.9807 - val_loss: 0.2687 - val_binary_accuracy: 0.9809\n",
      "Epoch 16/150\n",
      "23/23 [==============================] - 16s 689ms/step - loss: 0.0648 - binary_accuracy: 0.9807 - val_loss: 0.2432 - val_binary_accuracy: 0.9809\n",
      "Epoch 17/150\n",
      "23/23 [==============================] - 16s 682ms/step - loss: 0.0644 - binary_accuracy: 0.9808 - val_loss: 0.2235 - val_binary_accuracy: 0.9809\n",
      "Epoch 18/150\n",
      "23/23 [==============================] - 16s 688ms/step - loss: 0.0639 - binary_accuracy: 0.9808 - val_loss: 0.2008 - val_binary_accuracy: 0.9809\n",
      "Epoch 19/150\n",
      "23/23 [==============================] - 16s 682ms/step - loss: 0.0636 - binary_accuracy: 0.9809 - val_loss: 0.1800 - val_binary_accuracy: 0.9809\n",
      "Epoch 20/150\n",
      "23/23 [==============================] - 16s 685ms/step - loss: 0.0633 - binary_accuracy: 0.9809 - val_loss: 0.1645 - val_binary_accuracy: 0.9810\n",
      "Epoch 21/150\n",
      "23/23 [==============================] - 15s 677ms/step - loss: 0.0629 - binary_accuracy: 0.9809 - val_loss: 0.1449 - val_binary_accuracy: 0.9810\n",
      "Epoch 22/150\n",
      "23/23 [==============================] - 16s 688ms/step - loss: 0.0626 - binary_accuracy: 0.9810 - val_loss: 0.1363 - val_binary_accuracy: 0.9810\n",
      "Epoch 23/150\n",
      "23/23 [==============================] - 16s 689ms/step - loss: 0.0622 - binary_accuracy: 0.9810 - val_loss: 0.1237 - val_binary_accuracy: 0.9810\n",
      "Epoch 24/150\n",
      "23/23 [==============================] - 16s 684ms/step - loss: 0.0620 - binary_accuracy: 0.9810 - val_loss: 0.1110 - val_binary_accuracy: 0.9810\n",
      "Epoch 25/150\n",
      "23/23 [==============================] - 15s 675ms/step - loss: 0.0617 - binary_accuracy: 0.9811 - val_loss: 0.1033 - val_binary_accuracy: 0.9810\n",
      "Epoch 26/150\n",
      "23/23 [==============================] - 15s 676ms/step - loss: 0.0614 - binary_accuracy: 0.9811 - val_loss: 0.0946 - val_binary_accuracy: 0.9811\n",
      "Epoch 27/150\n",
      "23/23 [==============================] - 16s 682ms/step - loss: 0.0612 - binary_accuracy: 0.9811 - val_loss: 0.0866 - val_binary_accuracy: 0.9811\n",
      "Epoch 28/150\n",
      "23/23 [==============================] - 15s 676ms/step - loss: 0.0609 - binary_accuracy: 0.9812 - val_loss: 0.0846 - val_binary_accuracy: 0.9811\n",
      "Epoch 29/150\n",
      "23/23 [==============================] - 16s 683ms/step - loss: 0.0607 - binary_accuracy: 0.9812 - val_loss: 0.0786 - val_binary_accuracy: 0.9811\n",
      "Epoch 30/150\n",
      "23/23 [==============================] - 16s 683ms/step - loss: 0.0604 - binary_accuracy: 0.9812 - val_loss: 0.0769 - val_binary_accuracy: 0.9811\n",
      "Epoch 31/150\n",
      "23/23 [==============================] - 16s 679ms/step - loss: 0.0602 - binary_accuracy: 0.9812 - val_loss: 0.0738 - val_binary_accuracy: 0.9811\n",
      "Epoch 32/150\n",
      "23/23 [==============================] - 16s 680ms/step - loss: 0.0599 - binary_accuracy: 0.9813 - val_loss: 0.0709 - val_binary_accuracy: 0.9812\n",
      "Epoch 33/150\n",
      "23/23 [==============================] - 16s 684ms/step - loss: 0.0597 - binary_accuracy: 0.9813 - val_loss: 0.0696 - val_binary_accuracy: 0.9812\n",
      "Epoch 34/150\n",
      "23/23 [==============================] - 16s 687ms/step - loss: 0.0595 - binary_accuracy: 0.9813 - val_loss: 0.0694 - val_binary_accuracy: 0.9811\n",
      "Epoch 35/150\n",
      "23/23 [==============================] - 16s 685ms/step - loss: 0.0593 - binary_accuracy: 0.9814 - val_loss: 0.0682 - val_binary_accuracy: 0.9812\n",
      "Epoch 36/150\n",
      "23/23 [==============================] - 16s 682ms/step - loss: 0.0591 - binary_accuracy: 0.9814 - val_loss: 0.0672 - val_binary_accuracy: 0.9812\n",
      "Epoch 37/150\n",
      "23/23 [==============================] - 16s 680ms/step - loss: 0.0589 - binary_accuracy: 0.9814 - val_loss: 0.0663 - val_binary_accuracy: 0.9813\n",
      "Epoch 38/150\n",
      "23/23 [==============================] - 16s 692ms/step - loss: 0.0587 - binary_accuracy: 0.9815 - val_loss: 0.0655 - val_binary_accuracy: 0.9813\n",
      "Epoch 39/150\n",
      "23/23 [==============================] - 16s 687ms/step - loss: 0.0584 - binary_accuracy: 0.9815 - val_loss: 0.0649 - val_binary_accuracy: 0.9813\n",
      "Epoch 40/150\n",
      "23/23 [==============================] - 16s 682ms/step - loss: 0.0582 - binary_accuracy: 0.9815 - val_loss: 0.0642 - val_binary_accuracy: 0.9813\n",
      "Epoch 41/150\n",
      "23/23 [==============================] - 16s 689ms/step - loss: 0.0581 - binary_accuracy: 0.9816 - val_loss: 0.0646 - val_binary_accuracy: 0.9812\n",
      "890/890 [==============================] - 5s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "ACTIVATION = 'relu'\n",
    "BATCH_SIZE = 5000\n",
    "# Список для создания `Сallbacks` объектов. \n",
    "CALLBACKS_PARAMS: list[mu.CallbackParams] = [\n",
    "    {\n",
    "        'callback': tf.keras.callbacks.EarlyStopping,\n",
    "        'params': {\n",
    "            'monitor': 'val_loss',\n",
    "            'mode': 'min',\n",
    "            'min_delta': 0.01,\n",
    "            'patience': 10,\n",
    "            'restore_best_weights': True,\n",
    "        }\n",
    "    },\n",
    "]\n",
    "# None или результат `mu.create_callbacks(CALLBACKS_PARAMS)`\n",
    "CALLBACKS = mu.create_callbacks(CALLBACKS_PARAMS)\n",
    "DROPOUT = 0.5\n",
    "EPOCHS = 150\n",
    "KERNEL_REGULARIZER = None\n",
    "# Структура скрытых слоев в последовательной DNN.\n",
    "LAYERS_STRCT = [1024, 512, 1024]\n",
    "LEARNING_RATE = 0.001\n",
    "LOSS = mu.WeightedBinaryCrossentropy(\n",
    "    mu.calculating_class_weights(y.to_numpy())\n",
    ")\n",
    "# LOSS = mu.WeightedBinaryCrossentropy()\n",
    "# Число циклов с кросс-валидацией.\n",
    "N_REPEATS = 1\n",
    "# Число фолдов в кросс-валидации.\n",
    "N_SPLITS = 5\n",
    "# Параметры для формирования метрик.\n",
    "METRIC_TH_STEP = 0.01\n",
    "METRIC_TAU = 0.5\n",
    "# Список метрик, используемых для рассчета произовдительности модели.\n",
    "METRICS = [\n",
    "    mu.f1_score_micro,\n",
    "    mu.ia_f1_score_micro,\n",
    "    mu.metric_ia_closure(\n",
    "        metric_func=mu.ia_f1_score_weighted,  # type: ignore\n",
    "        metric_name='iaw_f1',\n",
    "        tau=METRIC_TAU,\n",
    "    ),\n",
    "    mu.metric_ia_closure(\n",
    "        metric_func=mu.ia_f1_score_weighted_max,  # type: ignore\n",
    "        metric_name='iaw_f1_max',\n",
    "        tau_arr=np.arange(METRIC_TH_STEP, 1, METRIC_TH_STEP),\n",
    "    )\n",
    "]\n",
    "RANDOM_STATE = 5917 # random.randint(0, 10_000)\n",
    "SHUFFLE = True\n",
    "VALIDATION_SPLIT: float | None = None\n",
    "VERBOSE = 1\n",
    "\n",
    "\n",
    "# Формирование фабрики скомпилированных моделей.\n",
    "mfabric = mu.ModelCompileFabric(\n",
    "    activation=ACTIVATION,\n",
    "    kernel_regularizer=KERNEL_REGULARIZER,\n",
    "    dropout=DROPOUT,\n",
    "    layers_strct=LAYERS_STRCT,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    loss=LOSS,\n",
    ")\n",
    "# Создаем прокси для обучения моделей.\n",
    "mproxy = mu.ProxyFitModel(\n",
    "    mfabric,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=CALLBACKS,\n",
    "    epochs=EPOCHS,\n",
    "    shuffle=SHUFFLE,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    verbose=VERBOSE,\n",
    ")\n",
    "# Оценка производительности модели через кросс-валидацию.\n",
    "results = mu.evaluate_model(\n",
    "    features=x.to_numpy(),\n",
    "    lbls=y.to_numpy(),\n",
    "    metrics=METRICS,  # type: ignore\n",
    "    ia_arr=ia_arr,\n",
    "    proxy_model=mproxy,\n",
    "    n_repeats=N_REPEATS,\n",
    "    n_splits=N_SPLITS,\n",
    "    random_state=RANDOM_STATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение результатов\n",
    "Сохранение результатов оценки производительности модели и сопутсвующих параметров. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл был дополнен\n"
     ]
    }
   ],
   "source": [
    "data_info_dict = {\n",
    "    'file_name_features': PATH_TO_FEATURES.name,\n",
    "    'file_name_labels': PATH_TO_LABELS.name,\n",
    "    'file_name_ia_arr': PATH_TO_IA_ARR.name,\n",
    "}\n",
    "model_params_dict = {\n",
    "    'activation': ACTIVATION,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'callbacks': (\n",
    "        CALLBACKS if CALLBACKS is None\n",
    "        else mu.create_callbacks_info(CALLBACKS_PARAMS)\n",
    "    ),\n",
    "    'dropout': DROPOUT,\n",
    "    'epochs': EPOCHS,\n",
    "    'kernel_regularizer': KERNEL_REGULARIZER,\n",
    "    'layers_strct': LAYERS_STRCT,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'loss': LOSS.name,\n",
    "    'n_repeats': N_REPEATS,\n",
    "    'n_splits': N_SPLITS,\n",
    "    'mean_epoch': mean_epochs(results[1]),\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'shuffle': SHUFFLE,\n",
    "    'validation_split': VALIDATION_SPLIT,\n",
    "}\n",
    "# Формируем словарь с текущей оценкой производительности модели\n",
    "# и сопутсвующими параметрами.\n",
    "model_eval_params: mu.ModelEvalParams = {\n",
    "    'data_info': data_info_dict,\n",
    "    'model_params': model_params_dict,\n",
    "    'scores': mu.get_scores_stats(results[0], ndigits=3),\n",
    "}\n",
    "cur_datetime = datetime.now().strftime('%Y_%d%b%H_%M_%S')\n",
    "# Записываем результаты текущей оценки производительности модели в файл.\n",
    "eval_log_to_json(\n",
    "    log_file=DIR_ROOT / 'experiments/eval.json',\n",
    "    params={f'dt{cur_datetime}': model_eval_params},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение loss-функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss\n",
      "binary_accuracy\n",
      "val_loss\n",
      "val_binary_accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f2d5a446680>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_1 = results[1][1]\n",
    "for key in history_1.history.keys():\n",
    "    print(key)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(history_1.history['loss'], label='loss')\n",
    "ax.plot(history_1.history['val_loss'], label='val_loss')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
