{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Корень проекта.\n",
    "DIR_ROOT = Path.cwd().parent.parent\n",
    "# Путь к удаленной директории с ресурсами: данные, модели и т.д.\n",
    "DIR_REMOTE: Path | None = Path('/home/admin/cafa/resources')\n",
    "\n",
    "if DIR_REMOTE is not None and DIR_REMOTE.exists():\n",
    "    DIR_RESOURCE = DIR_REMOTE\n",
    "else:\n",
    "    DIR_RESOURCE = DIR_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parser import ia_parser\n",
    "\n",
    "ia_dict = ia_parser(DIR_RESOURCE / 'data/raw/IA.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parser import obo_parser\n",
    "from graph import Graph\n",
    "\n",
    "obo_file = DIR_RESOURCE / 'data/raw/Train/go-basic.obo'\n",
    "\n",
    "ontologies = []\n",
    "for ns, terms_dict in obo_parser(obo_file).items():\n",
    "    ontologies.append(Graph(ns, terms_dict, ia_dict, orphans=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# конвертировать файл tsv в txt, убрать столбец с корневыми онтологиями, чтобы привести к формату авторского решения\n",
    "\n",
    "# train_terms = pd.read_csv(DIR_RESOURCE / 'data/raw/Train/train_terms.tsv', sep='\\t', header=None)\n",
    "\n",
    "# train_terms.drop(columns=[2], inplace=True)\n",
    "# train_terms = train_terms.iloc[1:]\n",
    "\n",
    "# train_terms.to_csv(DIR_RESOURCE / 'data/raw/Train/train_terms.txt', sep='\\t',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parser import gt_parser\n",
    "\n",
    "gt_file = DIR_RESOURCE / 'data/raw/Train/train_terms.txt'\n",
    "\n",
    "gt = gt_parser(gt_file, ontologies) # около 4Гб RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_step = 0.001\n",
    "\n",
    "tau_arr = np.arange(th_step, 1, th_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "До этой строки потрачено 6,24 Гб Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 19.2 GiB for an array with shape (92210, 27942) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m max_terms \u001b[39m=\u001b[39m \u001b[39m1500\u001b[39m \u001b[39m# количество онтологий, которое мы выбрали при обучении\u001b[39;00m\n\u001b[1;32m      9\u001b[0m dfs \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 11\u001b[0m prediction \u001b[39m=\u001b[39m pred_parser(file_name, ontologies, gt, prop, max_terms)\n\u001b[1;32m     12\u001b[0m df_pred \u001b[39m=\u001b[39m evaluate_prediction(prediction, gt, ontologies, tau_arr, args\u001b[39m.\u001b[39mnorm, args\u001b[39m.\u001b[39mthreads)\n\u001b[1;32m     13\u001b[0m df_pred[\u001b[39m'\u001b[39m\u001b[39mfilename\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m file_name\n",
      "File \u001b[0;32m~/cafa/julia/kaggle_CAFA/evaluator_for_cafa/parser.py:115\u001b[0m, in \u001b[0;36mpred_parser\u001b[0;34m(pred_file, ontologies, gts, prop_mode, max_terms)\u001b[0m\n\u001b[1;32m    113\u001b[0m onts \u001b[39m=\u001b[39m {ont\u001b[39m.\u001b[39mnamespace: ont \u001b[39mfor\u001b[39;00m ont \u001b[39min\u001b[39;00m ontologies}\n\u001b[1;32m    114\u001b[0m \u001b[39mfor\u001b[39;00m ns \u001b[39min\u001b[39;00m gts:\n\u001b[0;32m--> 115\u001b[0m     matrix[ns] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mzeros(gts[ns]\u001b[39m.\u001b[39;49mmatrix\u001b[39m.\u001b[39;49mshape, dtype\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mfloat\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    116\u001b[0m     ids[ns] \u001b[39m=\u001b[39m {}\n\u001b[1;32m    117\u001b[0m     \u001b[39mfor\u001b[39;00m term \u001b[39min\u001b[39;00m onts[ns]\u001b[39m.\u001b[39mterms_dict:\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 19.2 GiB for an array with shape (92210, 27942) and data type float64"
     ]
    }
   ],
   "source": [
    "from parser import pred_parser\n",
    "\n",
    "\n",
    "file_name = DIR_RESOURCE / 'data/submission/submission_1000.txt'\n",
    "prop = 'fill' # by default 'max', but author choosed fill\n",
    "max_terms = 1500 # количество онтологий, которое мы выбрали при обучении\n",
    "\n",
    "\n",
    "dfs = []\n",
    "\n",
    "prediction = pred_parser(file_name, ontologies, gt, prop, max_terms)\n",
    "df_pred = evaluate_prediction(prediction, gt, ontologies, tau_arr, args.norm, args.threads)\n",
    "df_pred['filename'] = file_name\n",
    "dfs.append(df_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs)\n",
    "\n",
    "# Save the dataframe\n",
    "df = df[df['cov'] > 0].reset_index(drop=True)\n",
    "df.set_index(['filename', 'ns', 'tau'], inplace=True)\n",
    "\n",
    "if args.ia is not None:\n",
    "    columns = [\"cov\", \"pr\", \"rc\", \"f\", \"wcov\", \"wpr\", \"wrc\", \"wf\", \"mi\", \"ru\", \"s\"]\n",
    "else:\n",
    "    columns = [\"cov\", \"pr\", \"rc\", \"f\"]\n",
    "df.to_csv('{}/evaluation_all.tsv'.format(out_folder), columns=columns, float_format=\"%.5f\", sep=\"\\t\")\n",
    "\n",
    "# Calculate harmonic mean across namespaces for each evaluation metric\n",
    "for metric, cols in [('f', ['rc', 'pr']), ('wf', ['wrc', 'wpr']), ('s', ['ru', 'mi'])]:\n",
    "    if metric in columns:\n",
    "        index_best = df.groupby(level=['filename', 'ns'])[metric].idxmax() if metric in ['f', 'wf'] else df.groupby(['filename', 'ns'])[metric].idxmin()\n",
    "\n",
    "        df_best = df.loc[index_best]\n",
    "        df_best['max_cov'] = df.reset_index('tau').loc[[ele[:-1] for ele in index_best]].groupby(level=['filename', 'ns'])['cov'].max()\n",
    "        df_best.to_csv('{}/evaluation_best_{}.tsv'.format(out_folder, metric),\n",
    "                        columns=columns + [\"max_cov\"], float_format=\"%.5f\", sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
